# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.1.0/)

## [20.14.0] 2026-01-30

### Added

- data_exploration:
    - `filter_subset()`, Filters a DataFrame based on a dictionary of column-value conditions, with options to drop filter columns and reset index.

## [20.13.0] 2026-01-27

### Changed

- ML_evaluation_captum:
    - `captum_feature_importance()`, calculate and save feature importance percentages alongside scaled absolute values in the CSV output for better interpretability. The plot now displays relative importance percentages on the x-axis for clearer understanding of feature contributions.

## [20.12.0] 2026-01-27

### Changed

- ML_evaluation_captum:
    - `captum_feature_importance()`, added `verbose` parameter to control logging verbosity. Improved feature importance plot aesthetics with standardized x-axis scale from 0 to 1.

## [20.11.0] 2026-01-15

### Added

- ML_trainer:
    - Trainer classes now have the method `.load_checkpoint()` to load and set a specific checkpoint into the trainer.

### Changed

- keys:
    - Checkpoints generated by the `DragonModelCheckpoint` callback now use the name `DragonCheckpoint` in the saved .pth files.

## [20.10.0] 2026-01-13

### Changed

- Changed regression plot size default for better readability.
- ML_evaluation_captum:
    - `captum_feature_importance()`, feature importance plot titles now use the original target names for clarity.

## [20.9.0] 2026-01-08

### Changed

- ML_evaluation:
    - Added helper function to abbreviate long class/target names in metrics.
    - Enhance docstrings and logging.
    - Classification metrics: Anchor calibration plots start and end points to (0,0) and (1,1) for better visualization.

## [20.8.0] 2026-01-05

### Changed

- ML_evaluation:
    - Enhanced plot aesthetics for classification evaluation plots.
    - `multi_label_classification_metrics()`, added classification report heatmap visualization for an overall summary of multi-label classification performance.

### Added

- New module: "resampling"
    - `DragonResampler`, Class for resampling single-label binary or multi-class classification datasets.
        - `balance_classes()`, Downsamples majority class to match minority class size based on a specified ratio.
        - `describe_balance()`, Prints a statistical summary of the target distribution.
    - `DragonMultiResampler`, Class for resampling multi-label binary classification datasets.
        - `downsample_all_negatives()`, Downsamples rows where all target labels are negative based on a specified ratio.
        - `balance_powerset()`, Balances the dataset based on unique label combinations (Powerset).
        - `describe_balance()`, Prints a statistical summary of the multi-label target distribution.
- data_exploration:
    - `check_class_balance()`, Analyzes and visualizes class balance for single-label binary, multi-class, and multi-label binary classification targets.
    - `encode_classification_target()`, Encodes a classification target column and saves the class mapping to a JSON file.

## [20.7.1] 2026-01-04

### Fixed

- utilities:
    - `translate_dataframe_columns()`, fixed bug when translating Polars DataFrames where missing columns would raise an error.

## [20.7.0] 2026-01-04

### Added

- utilities:
    - `translate_dataframe_columns()`, Translates DataFrame column names based on a provided translation mapping.
    - `create_translation_template()`, Creates a template JSON file for column name translations.
    - `audit_column_translation()`, Audits the translation mapping against the DataFrame to identify missing or extra columns.

## [20.6.0] 2026-01-02

### Added

- ETL_cleaning:
    - `save_category_counts()`, Saves the counts and percentages of unique values in complete dataframes or specific columns to a text file.

### Changed

- ML_configuration:
    - Modified `calibration_bins` parameter to accept both integer values and 'auto' string in the following metrics format classes:
        - `BinaryClassificationMetricsFormat`
        - `MultiClassClassificationMetricsFormat`
        - `BinaryImageClassificationMetricsFormat`
        - `MultiClassImageClassificationMetricsFormat`
        - `MultiLabelBinaryClassificationMetricsFormat`
- ML_evaluation:
    - Updated calibration plot functions to handle the new `calibration_bins` parameter accepting both integer and 'auto' string.
- ETL_cleaning:
    - `DragonColumnCleaner`, added parameter `exact_matches` to allow dictionary-based exact value replacements before applying regex rules for improved performance.
    - `DragonColumnCleaner.preview()`, added `show_distribution` parameter to optionally generate a category count report for the column after cleaning.
    - `DragonDataFrameCleaner`, modified internal cleaning logic to apply exact matches before regex rules for better performance.

## [20.5.0] 2025-12-30

### Changed

- ML_optimization:
    - `DragonParetoOptimizer.run()`, added `plots_and_log` parameter to control whether to generate plots and logs during optimization. Useful for multi-run scenarios to avoid redundant outputs.
- data_exploration:
    - `apply_feature_schema()`, added `verbose` parameter to control logging verbosity during schema application.

### Added
- data_exploration:
    - `reconstruct_from_schema()`, Reconstructs a DataFrame based on a given FeatureSchema, ensuring correct column order and encoding.
- schema:
    - `FeatureSchema.save_description()`, Saves the schema description to a text file.

## [20.4.0] 2025-12-30

- Enhance classification plots default aesthetics.

### Changed

- ML_optimization:
    - `DragonParetoOptimizer.save_solutions()`, added `csv_if_exists` parameter to control behavior when the CSV file already exists.
- IO_tools:
    - `train_logger()`, allow None value for `model_parameters` to skip logging model parameters.

## [20.3.0] 2025-12-28

- Non-breaking internal refactoring and logging improvements.

### Changed

- ML_trainer:
    - `.finalize_model_training()`, now automatically outputs a report on the contents of the finalized .pth file.
- ML_optimization:
    - `DragonOptimizer`, now initialized from a `DragonOptimizerConfig` instance for consistent configuration management. Simplifying method signatures.

### Added

- ML_configuration:
    - `DragonOptimizerConfig`, Configuration class for single-objective optimization tasks.

## [20.2.0] 2025-12-26

### Changed

- ML_datasetmaster:
    - `DragonDataset`, converts single regression target columns to 2D tensors to comply with best practices in PyTorch.

### Fixed

- ML_scaler:
    - `DragonScaler.scale()`, now correctly handles 1D input tensors by reshaping them to 2D for scaling operations and reshaping back to 1D afterward. (Defensive implementation)
    - `DragonScaler.inverse_scale()`, now correctly handles 1D input tensors by reshaping them to 2D for inverse scaling operations and reshaping back to 1D afterward. (Defensive implementation)

## [20.1.1] 2025-12-25

### Changed

- ML_configuration:
    - `DragonTrainingConfig`, added new train parameters:
        - `device`
        - `finalized_filename`
        - `task`, validates against `MLTaskKeys` for robustness.

## [20.1.0] 2025-12-25

### Added

- ML_chain:
    - `derive_next_step_schema()`, derives the next step FeatureSchema for chained models based on the current schema and model inference handler.

### Changed

- ML_chain:
    - `DragonChainOrchestrator.update_with_inference()`, now appends prediction columns with a standardized prefix for consistency across chained models.
    - `augment_dataset_with_predictions()`, now appends prediction columns with a standardized prefix for consistency across chained models.

## [20.0.1] 2025-12-25

### Changed

- schema:
    - `FeatureSchema.to_json()`, If the target directory does not exist, it will be created automatically.

### Fixed

- MICE:
    - `DragonMICE.run_pipeline()`, fixed a bug when monitoring imputed columns. Now correctly identifies columns with NaN values in the input DataFrame.
    - `get_convergence_diagnostics()`, enhanced logic to reduce computational bottlenecks.

## [20.0.0] 2025-12-25

### Changed

- Internal refactoring and optimizations for all modules.
- data_exploration:
    - `encode_categorical_features()`, revamped to return both the encoded DataFrame and the mapping dictionary. Improved handling of NaN values and added detailed logging. Reduced parameters for robustness.
- Module "VIF_factor" renamed to "VIF".
- Module "MICE_imputation" renamed to "MICE". 
    - `DragonMICE`, class updated to hide internal attributes and methods. Added detailed docstrings for public methods. Added validation steps for robustness.
    - `run_mice_imputation()` function deprecated.
- ML_utilities:
    - `ArtifactFinder`, renamed to `DragonArtifactFinder`.
- Modules "ML_evaluation", "ML_sequence_evaluation", "ML_vision_evaluation", and "ML_evaluation_multi" merged into "ML_evaluation".
- Modules "ML_optimization" and "ML_optimization_pareto" merged into "ML_optimization".
- Modules "ML_models" and "ML_models_advanced" merged into "ML_models".
    - `save` methods have been unified and renamed to `save_architecture()`.
    - `load` class methods have been unified and renamed to `load_architecture()`.
- Module "ML_sequence_inference" renamed to "ML_inference_sequence".
- Module "ML_vision_inference" renamed to "ML_inference_vision".
- Modules "ML_datasetmaster", "ML_sequence_datasetmaster", and "ML_vision_datasetmaster" merged into "ML_datasetmaster".
- Module "ML_chaining_inference" moved into "ML_inference".
- Module "ML_chaining_utilities" renamed to "ML_chain".
- Module "ML_sequence_models" renamed to "ML_models_sequence".
- Module "ML_vision_models" renamed to "ML_models_vision".
- ML_configuration:
    - Renamed configuration classes for evaluation metrics.
- schema:
    - `FeatureSchema`, new class method `from_model_architecture()` to load a FeatureSchema directly from a model architecture file.

### Added

- data_exploration:
    - `split_continuous_categorical_targets()`, splits a DataFrame into 3 dataframes: continuous features, categorical features, and targets.

### Removed

- ML_models_pytab: Removed wrappers for pytorch_tabular models.
- ML_configuration_pytab: Removed configuration classes for pytorch_tabular wrapper models.

## [19.14.0] 2025-12-22

### Changed

- data_exploration:
    - `plot_continuous_vs_target()`, revamped to accept a DataFrame of continuous features and a DataFrame of targets. Generates scatter plots with regression lines for each feature-target pair. Improved data alignment and NaN handling.
    - `plot_categorical_vs_target()`, revamped to accept a DataFrame of categorical features and a DataFrame of targets. Generates box plots for each categorical feature against each numeric target. Improved data alignment and NaN handling.
    - `summarize_dataframe()`, added 'Completeness %' column to provide a quick overview of data completeness for each column. Customized percentiles in numeric summary statistics for more detailed insights.
    - `plot_correlation_matrix()`, enhanced heatmap visualization with anchored color scale from -1 to 1 for better interpretability of correlations.

## [19.13.0] 2025-12-22

### Changed

- data_exploration:
    - `plot_value_distributions()`, increased default max categories from 50 to 100, changed fill_na_with default to "MISSING DATA", updated color palette for count plots to "Oranges", and refined docstrings for clarity. Removed automatic detection of categorical columns based on cardinality threshold; now relies solely on user input for categorical columns for consistency.
    - `plot_categorical_vs_target()`, removed `plot_type` parameter to streamline functionality. Now exclusively generates box plots for categorical vs. numeric target visualizations. Updated docstrings and logging messages to reflect this change.
    - `drop_macro()`, missing data report and plots are now saved in a dedicated "Missing Report" subdirectory within the specified log directory for better organization. 

## [19.12.2] 2025-12-22

### Fixed

- Enhance logging messages and docstrings in various modules for better clarity and usability.

## [19.12.1] 2025-12-20

### Changed

- IO_tools:
    - `train_logger()`, enhanced validation for `train_config` and `model_parameters` to ensure proper dictionary conversion.
- ML_configuration:
    - `DragonTrainingConfig`, added detailed docstrings for better clarity on parameters and usage. Removed callback-specific parameters to promote compatibility with different callback implementations.
- ML_finalize_handler:
    - `FinalizedFileHandler`, improved warning messages when loading non-standard finalized files. Now displays the actual keys found in the file for easier debugging.

## [19.12.0] 2025-12-19

### Changed

- ML_callbacks:
    - `DragonModelCheckpoint`, revamped to monitor the training loss, validation loss, or both. Supports saving the best three checkpoints based on the monitored metric.
    - `DragonEarlyStopping`, split into two distinct classes for more specialized early stopping strategies.
        - `DragonPatienceEarlyStopping`, stops training after a specified number of epochs without improvement.
        - `DragonPrecheltEarlyStopping`, implements the Prechelt early stopping method based on training and validation loss trends.
    - `DragonLRScheduler`, split into two distinct classes for more specialized learning rate scheduling.
        - `DragonReduceLROnPlateau`, reduces the learning rate when a metric has stopped improving. Wrapper for PyTorch's `ReduceLROnPlateau`.
        - `DragonScheduler`, general-purpose learning rate scheduler that can wrap any PyTorch scheduler (except `ReduceLROnPlateau`) to fit the Dragon ML training loop.

### Added

- keys:
    - `TaskKeys`, consistent task key names for ML tasks in the Dragon ML pipeline.
- path_manager:
    - `clean_directory()`, removes all files and subdirectories within a specified directory.
    - `safe_move()`, safely moves a file or directory to a new location with options for renaming and overwriting.

## [19.11.0] 2025-12-18

### Changed

- path_manager:
    - `list_files_by_extension()`, added `raise_on_empty` parameter to control error raising when no files are found.
    - `list_csv_paths()`, added `raise_on_empty` parameter to control error raising when no CSV files are found.
    - `list_subdirectories()`, added `raise_on_empty` parameter to control error raising when no subdirectories are found.
- ML_utilities:
    - `ArtifactFinder`, added `strict` parameter to enforce strict loading of all artifacts. If False, missing artifacts return None silently.

## [19.10.0] 2025-12-17

- Remove package bundlers options (PyInstaller/Nuitka). These can be installed separately if needed.
- Add development dependencies to pyproject.toml for easier setup of development environments.
- Update README.md to reflect the current state of the package.

### Changed

- ML_configuration:
    - `DragonParetoConfig`, modified `continuous_bounds_map` parameter to accept a path to a directory containing the "optimization_bounds.json" file.
- ML_optimization_pareto:
    - `DragonParetoOptimizer`, modified to load continuous bounds from a file if a path is provided in the configuration.

### Fixed

- optimization_tools:
    - `make_continuous_bounds_template()`, fixed missing import.
    - `load_continuous_bounds_template()`, fixed missing import.

## [19.9.0] 2025-12-16

### Changed

- path_manager:
    - All paths are stored as absolute paths for consistency.
    - `DragonPathManager`, added `strict_to_root` parameter to enforce all paths to be within the package root directory.
    - `DragonPathManager.status()`, revamped output format for better readability.

## [19.8.2] 2025-12-15

### Fixed

- Fix minor import bug in the new "keys" module.

## [19.8.1] 2025-12-15

### Added

- New module "keys" to use consistent key names across the package.
    - `InferenceKeys`, used by inference handlers.
    - `CheckpointCallbackKeys`, used by the checkpoint callback.
    - `FinalizedFileKeys`, used for finalized model files.

## [19.8.0] 2025-12-15

### Changed

- ML_configuration:
    - `DragonTrainingConfig`, added support for arbitrary keyword arguments to enhance flexibility and future-proofing.
- ML_optimization_pareto:
    - `DragonParetoOptimizer`, Initialized from a `DragonParetoConfig` instance for consistent configuration management. Simplifying method signatures.
    - `DragonParetoOptimizer.run()`, now plots the genetic algorithm history for each target.

### Added

- ML_configuration:
    - `DragonParetoConfig`, Configuration class for Pareto optimization tasks.

## [19.7.0] 2025-12-15

### Changed

- ML_configuration: Added font size configuration to metrics format classes for better plot customization:
    - `RegressionMetricsFormat`
    - `MultiTargetRegressionMetricsFormat`
    - `BinaryClassificationMetricsFormat`
    - `MultiClassClassificationMetricsFormat`
    - `BinaryImageClassificationMetricsFormat`
    - `MultiClassImageClassificationMetricsFormat`
    - `MultiLabelBinaryClassificationMetricsFormat`
- ML_evaluation:
    - `classification_metrics()`, added support for font size configuration.
    - `regression_metrics()`, added support for font size configuration.
- ML_evaluation_multi:
    - `multi_target_classification_metrics()`, added support for font size configuration.
    - `multi_target_regression_metrics()`, added support for font size configuration.

## [19.6.0] 2025-12-14

### Added

- IO_tools:
    - `save_json()`, saves a dictionary or list to a JSON file.
    - `load_json()`, loads a JSON file with strict root type validation.
- optimization_tools:
    - `make_continuous_bounds_template()`, creates a JSON template for manual entry of continuous feature optimization bounds.
    - `load_continuous_bounds_template()`, loads the continuous feature bounds template from JSON.

### Changed

- optimization_tools:
    - `create_optimization_bounds()`, modified `continuous_bounds_map` parameter to accept both tuples and lists for bounds. Added validation to ensure correct types and lengths.

## [19.5.0] 2025-12-13

### Changed

- Module: "custom_logger" renamed to "IO_tools".
- IO_tools:
    - `train_logger()`, Modified parameters to log training configurations, model parameters, and training history to a JSON file.
- ML_utilities:
    - `ArtifactFinder`, added support for loading a FeatureSchema from the model artifacts directory.

## [19.4.0] 2025-12-12

### Changed

- schema:
    - `create_guischema_template()`, enhanced validation for multi-binary groups in GUISchema:
        - Empty groups will be skipped with a warning.
        - Columns not found in FeatureSchema will be skipped with a warning.
        - GUISchema.json, updated to use consistent key names.

- GUI_tools:
    - `DragonFeatureMaster.from_guischema()`, updated to use consistent key names in GUISchema.json. Old keys are not supported.

### Added

- data_exploration:
    - `apply_feature_schema()`, Aligns the input DataFrame with the provided FeatureSchema.
- schema:
    - `make_multibinary_groups()`, Generates multi-binary groups for the GUISchema based on column name patterns in the FeatureSchema.

## [19.3.0] 2025-12-11

### Changed

- ETL_engineering:
    - `MultiNumberExtractor`, updated default regex pattern to match only positive numbers for consistency.
    - `MultiBinaryDummifier`, updated regex handling for clean column names, allowing hyphens.

## [19.2.4] 2025-12-11

- Set Python version requirement to 3.12.* in the package metadata.

## [19.2.3] 2025-12-11

- Migrated environment to use the UV package manager.

## [19.2.2] 2025-12-10

### Fixed

- ETL_cleaning:
    - `save_unique_values()`, fixed a bug that created an empty category from empty strings.

## [19.2.1] 2025-12-10

### Fixed

- optimization_tools: 
    - `plot_optimal_feature_distributions()` and `plot_optimal_feature_distributions_from_dataframe()`, always rotate x-ticks for categorical clarity.

### Changed

- ETL_cleaning:
    - `DragonColumnCleaner`, changed default `case_insensitive` parameter to `False` for consistency.
    - `DragonDataFrameCleaner`, changed default batch size for regex rules to 150 for memory efficiency.
    - `DragonDataFrameCleaner.load_clean_save()`, added `rule_batch_size` parameter to split regex rules into smaller chunks for memory efficiency.
    - `DragonColumnCleaner.preview()`, added `rule_batch_size` parameter to split regex rules into smaller chunks for memory efficiency.

## [19.2.0] 2025-12-09

### Added

- ETL_cleaning:
    - `drop_macro_polars()`, High-performance implementation of iterative row/column pruning using Polars.
    - `DragonColumnCleaner.preview()`, preview cleaning on a column without modifying the original data.

### Changed

- ETL_cleaning:
    - `basic_clean_drop()`, now uses `drop_macro_polars()` for improved performance with large datasets.
    - `DragonDataFrameCleaner`, internal cleaning logic optimized for Polars DataFrames and LazyFrames.`

## [19.1.0] 2025-12-08

### Changed

- ETL_engineering:
    - `BinaryTransformer`, now supports regex patterns.
    - `MultiBinaryDummifier`, now supports regex patterns.
    - `KeywordDummifier`, now supports regex patterns.
    - `NumberExtractor`, robust default regex to match numbers in various formats.
    - `MultiNumberExtractor`, robust default regex to match numbers in various formats.
    - `TemperatureExtractor`, robust default regex to match temperature values in various formats.
    - `MultiTemperatureExtractor`, robust default regex to match temperature values in various formats.

## [19.0.1] 2025-12-05

### Changed

- ETL_cleaning:
    - `save_unique_values()`, adds an optional parameter to create separators between unique values in the output file.

### Fixed

- utilities:
    - `save_dataframe_filename()`, fixed a bug when saving polars dataframes.

## [19.0.0] 2025-12-04

- Major release introducing model chaining capabilities for sequential ML workflows.

### Added

- New module: "ML_chaining_utilities"
    - `augment_dataset_with_predictions()`, Augments a DataFrame with model predictions as new columns.
    - `augment_dataset_with_predictions_multi()`, Augments a DataFrame with predictions from multiple models.
    - `prepare_chaining_dataset()`, Prepares a DataFrame for chaining by separating features and targets.
    - `DragonChainOrchestrator`, Manages the data flow for a sequential chain of ML models (Model 1 -> Model 2 -> ... -> Model N).

- New_module: "ML_chaining_inference"`
    - `DragonChainInference`, Chains multiple model inference handlers to perform a unified inference process.

### Changed

- ML_optimization_pareto:
    - `_ParetoFitnessEvaluator`, now supports both standard `DragonInferenceHandler` and the new `DragonChainInference` for multi-objective optimization.
    - `DragonParetoOptimizer`, updated to handle chained inference scenarios seamlessly.

## [18.13.0] 2025-12-04

### Changed

- ML_optimization_pareto:
    - `DragonParetoOptimizer.save_solutions()`, added `float_precision` parameter to control decimal places for float columns when saving solutions.
- data_exploration:
    - `show_null_columns()`, added `use_all_columns` parameter to include all columns in the summary and plot, even those with no missing values.
    - `drop_macro()`, calls `show_null_columns()` with `use_all_columns=True` to visualize all columns before and after cleaning.
- ETL_cleaning:
    - `basic_clean_drop()`, calls `data_exploration.show_null_columns()` with `use_all_columns=True` to visualize all columns before and after cleaning.

## [18.12.1] 2025-12-03

- Internal optimizations and logging improvements.

## [18.12.0] 2025-12-03

### Added

- New module: "plot_fonts"
    - `configure_cjk_fonts()`, configures Matplotlib to use CJK fonts for proper rendering of Chinese, Japanese, and Korean characters in plots.

### Fixed

- data_exploration:
    - `drop_rows_with_missing_data()`, fixed an edge case bug where all rows were dropped when passing an empty list of columns to check.

## [18.11.0] 2025-12-03

### Changed

- data_exploration:
    - `show_null_columns()`, optional plot output to visualize missing data per column.
    - `drop_macro()`, generates plots before and after cleaning to visualize missing data.

## [18.10.1] 2025-12-03

- Minor logging fixes.

## [18.10.0] 2025-12-02

### Added

- optimization_tools:
    - `plot_optimal_feature_distributions_from_dataframe()`, Plots feature distributions from a given DataFrame of optimal solutions.

### Changed

- ML_optimization_pareto:
    - `DragonParetoOptimizer.run()`, uses the new `plot_optimal_feature_distributions_from_dataframe()` function to plot input feature distributions directly from the DataFrame of optimal solutions.
    - `DragonParetoOptimizer.save_solutions()`, optionally saves to a SQL database.

## [18.9.1] 2025-12-02

### Fixed

- ML_optimization_pareto:
    - `DragonParetoOptimizer.save_solutions()`, added validation to ensure integer casting only applies to continuous columns according to the FeatureSchema.

## [18.9.0] 2025-12-02

### Changed

- math_utilities:
    - `discretize_categorical_values()`, now returns float values for the entire array to preserve precision in mixed-type arrays.
- ML_optimization_pareto:
    - `DragonParetoOptimizer.save_solutions()`, save solutions with optional value casting for integer columns.
    - `DragonParetoOptimizer.run()`, no longer saves solutions automatically. Use `save_solutions()` method instead.

## [18.8.1] 2025-12-01

### Changed

- GUI_tools:
    - `DragonFeatureMaster.from_guischema()`, loads the GUISchema file from a given directory.

### Fixed

- schema:
    - `FeatureSchema.from_json()`, added path validation to fail early in case of an error.

## [18.8.0] 2025-12-01

### Added

- schema:
    - `create_guischema_template()`, generates a boilerplate 'GUISchema.json' file based on a FeatureSchema and additional parameters.
- GUI_tools:
    - `DragonFeatureMaster.from_guischema()`, loads configuration from a 'GUISchema.json' file.

## [18.7.0] 2025-12-01

### Changed

- ML_optimization_pareto:
    - `DragonParetoOptimizer.run()`, no longer generates 3D plots by default.
    - `DragonParetoOptimizer.plot_pareto_3d()`, generate 3D interactive plots. Accepts an optional `hue_target` parameter to color points based on a specific target.

### Fixed

- optimization_tools:
    - `plot_optimal_feature_distributions()`, fixed a bug when plotting the legend for 'target'.

## [18.6.1] 2025-12-01

### Changed

- data_exploration:
    - `reconstruct_multibinary()`, now returns a tuple with the new DataFrame and a list of modified columns.

## [18.6.0] 2025-12-01

### Added

- New dependency: `plotly`, for interactive plots.
- ML_optimization_pareto:
    - `DragonParetoOptimizer._plot_pareto_3d()`, 3D interactive HTML output using Plotly.
- data_exploration:
    - `reconstruct_multibinary()`, identifies binary columns matching a regex pattern and encodes them.

### Changed

- ML_optimization_pareto:
    - `DragonParetoOptimizer._plot_pareto_3d()`, improved static 3D plot aesthetics with enhanced labeling and layout.
    - `DragonParetoOptimizer._plot_pareto_2d()`, improved 2D plot aesthetics with enhanced labeling and layout.
    - `DragonParetoOptimizer._plot_parallel_coordinates()`, improved plot aesthetics with enhanced labeling and layout.
- data_exploration:
    - `reconstruct_binary()`, allows overwriting existing columns when encoding.

### Fixed

- optimization_tools:
    - `plot_optimal_feature_distributions()`, improved data handling to prevent SettingWithCopyWarning in pandas.

## [18.5.1] 2025-11-28

- Minor logging fixes

## [18.5.0] 2025-11-28

### Changed

- Improved logging output in all modules.
- data_exploration:
    - `encode_categorical_features()`, added validation to check for constant columns during the encoding process.

### Renamed

- Module "handle_excel" renamed to "excel_handler"

### Fixed

- ML_optimization_pareto:
    - `DragonParetoOptimizer.run()`, fixed a bug when trying to work on data from a read-only tensor.


## [18.4.0] 2025-11-28

### Added

- New module: "ML_finalize_handler", implementing the `FinalizedFileHandler` class.
    - Handles loading and validation of finalized PyTorch model artifacts.
    - Robustly handles legacy (weights-only) schemas as a fallback.
    - Ensures safe CPU-first loading before device transfer.

- ML_configuration:
    - `FinalizeSequenceSequencePrediction`, specific configuration to create a finalized-file
    - `FinalizeSequenceValuePrediction`, specific configuration to create a finalized-file
    - All finalizer classes add the specific training task.

### Changed

- ML_inference:
    - `DragonInferenceHandler`: Refactored to use `FinalizedFileHandler`.
        - The `task` argument is now optional (automatically inferred from file metadata).
        - Improved device handling by loading state dictionary on CPU first.

- ML_vision_inference:
    - `DragonVisionInferenceHandler`: Refactored to use `FinalizedFileHandler`.
        - The `task` argument is now optional.

- ML_sequence_inference:
    - `DragonSequenceInferenceHandler`: Refactored to use `FinalizedFileHandler`.
        - The `prediction_mode` argument is now optional.

- ML_trainer: Added support for updated finalizer configuration files.

### Deleted

- ML_configuration:
    - `FinalizeSequencePrediction`, replaced by more specific configuration classes.

## [18.3.1] 2025-11-28

### Fixed

- Minor public API cleaning.

- ML_utilities:
    - `ArtifactFinder`, correctly exposes the model architecture path.

## [18.3.0] 2025-11-27

### Added

- New module: "schema", exposing the `FeatureSchema` class.
    - `FeatureSchema.to_json()`, Saves the 'FeatureSchema.json' to a directory. 
    - `FeatureSchema.from_json()`, Loads the 'FeatureSchema.json' from a directory.

### Deleted

- serde: FeatureSchema serialization.
    - `serialize_schema()`
    - `deserialize_schema()` 

## [18.2.0] 2025-11-27

- Fix package setuptools build bug.

### Changed

- ML_utilities:
    - `find_model_artifacts()` renamed to `find_model_artifacts_multi()` to better reflect its functionality over multiple directories.

### Added

- ML_utilities:
    - `ArtifactFinder`, finds, processes, and returns model training artifacts from a target directory.

## [18.1.2] 2025-11-27

- Internal reorganization of modules.

## [18.1.1] 2025-11-27

### Fixed

- ML_models_advanced: Bug with class inheritance. Method resolution order (MRO) error.

## [18.1.0] 2025-11-27

### Added

- custom_logger:
    - `train_logger()`, for quickly saving training logs to JSON.

### Added

- ML_models_advanced: Added to all models
    - Enhanced docstring for model initialization.
    - Added `__repr__` following PyTorch format for model architecture representation.

## [18.0.0] 2025-11-26

### Added

- ML_utilities:
    - `build_optimizer_params()`, groups model parameters formatted for PyTorch optimizers.

- Revamped module with native model implementations "ML_models_advanced":
    - `DragonGateModel`
    - `DragonNodeModel`
    - `DragonAutoInt`
    - `DragonTabNet`

### Changed

- Clean public APIs in all modules.
- Package dependency: `pytorch_tabular` will not be included by default in the core `ML` installation. Use the additional flag `py-tab` if needed.
- ML_models_pytab, model wrappers moved to this module.
    - `PyTabGateModel`
    - `PyTabTabNet`
    - `PyTabAutoInt`
    - `PyTabNodeModel`
- ML_configuration_pytab, configuration classes moved to this module.
    - `PyTabGateParams`
    - `PyTabNodeParams`
    - `PyTabTabNetParams`
    - `PyTabAutoIntParams`

## [17.4.0] 2025-11-26

### Added

- ML_configuration:
    - added `.to_log()` method for `[Model]Params` classes and `DragonTrainingConfig` to safely create a dictionary suitable for JSON logs.

### Changed

- ML_scaler:
    - `DragonScaler.fit()` now uses the Welford's algorithm for numerical stability and data scalability.

### Fixed

- ML_models_advanced:
    - Silence pytorch_tabular logger up to Error level.
    - `DragonNodeModel`, add missing configuration values to match the API.

## [17.3.1] 2025-11-25

### Changed

- ML_models_advanced:
    - `DragonTabNet`, added mask_type function parameter
- ML_configuration:
    - `DragonTabNetParams`, updated parameters to match model.

### Fixed

- ML_models_advanced:
    - `DragonNode`, changed 'entmax' to 'entmax15' as required by pytorch_tabular
- ML_configuration:
    - `DragonNodeParams`, updated parameters to match model.

## [17.3.0] 2025-11-25

### Fixed

- ML_datasetmaster:
    - `DragonDatasetMulti`, set a default `id` attribute at initialization to automate scaler file saving.

### Added

- ML_evaluation_captum:
    - `captum_feature_importance()`, add a logger after each successful plot and report creation.
- ML_models_advanced:
    - `DragonTabNet`, Adapter for Google's TabNet (Attentive Interpretable Tabular Learning).
    - `DragonAutoInt`, Adapter for AutoInt (Automatic Feature Interaction Learning).
- ML_configuration:
    - `DragonTrainingConfig`, Configuration file for training stage.
    - Model-specific parameter configurations:
        - `DragonMLPParams`
        - `DragonAttentionMLPParams`
        - `DragonMultiHeadAttentionNetParams`
        - `DragonTabularTransformerParams`
        - `DragonGateParams`
        - `DragonNodeParams`
        - `DragonTabNetParams`
        - `DragonAutoIntParams`

### Changed

- ML_evaluation:
    - `regression_metrics()`, new default plot size (9, 6).
- ML_evaluation_multi:
    - `multi_target_regression_metrics()`, new default plot size (9, 6).
- ML_models_advanced:
    - `DragonNodeModel`, updated to run with pytorch_tabular version > 1.0. Important: The model must perform a initialization on the CPU using its method `perform_data_aware_initialization()` before training.
    - `DragonGateModel`, updated to run with pytorch_tabular version > 1.0. 
- ML_callbacks:
    - `DragonModelCheckpoint`, modified default checkpoint filename.
- ML_datasetmaster:
    - `DragonDataset`, support for target scaler (regression) and feature scaler.
    - `DragonDatasetMulti`, support for target scaler (regression) and feature scaler.
- ML_sequence_datasetmaster:
    - `DragonDatasetSequence`, save scaler using the new format. Added property methods: `train_dataset`, `validation_dataset`, `test_dataset`.
- ML_vision_datasetmaster:
    - Added new property methods to the dataset classes: `train_dataset`, `validation_dataset`, `test_dataset`.
- ML_inference:
    - `DragonInferenceHandler`, support for target scaler.
- ML_sequence_inference:
    - `DragonSequenceInferenceHandler`, support for target scaler.
- ML_scaler:
    - `DragonScaler`, new method `fit_tensor()`, useful for targets or small datasets.
- ML_trainer:
    - `DragonTrainer`, support for target scaler during evaluation (regression).
    - `DragonSequenceTrainer`, support for scaler during evaluation.

### Deprecated

- ML_evaluation_multi:
    - `multi_target_shap_summary_plot()`, deprecated function. use Captum explanation instead.

## [17.2.0] 2025-11-21

### Changed

- New modular structure:
    - `[ML]`, includes all scripts compatible with PyTorch.
    - `[ensemble]`, includes all scripts compatible with XGBoost and LightGBM.
- MICE_imputation:
    - `DragonMICE`, added support for imputing target values.

### Deleted

- Project flags:
    - `[extras]`
    - `[py-tab]`
    - `[captum]`

### Fixed

- utilities:
    - `save_dataframe_filename()` minor syntax bug for polars '.strip()' to '.strip_chars()'

## [17.1.0] 2025-11-21

### Added

- Package install flag `[extras]`, to install pytorch_tabular and captum. 

- New module: "ML_optimization_pareto"
    - `DragonParetoOptimizer`, Pareto fronts optimization for multi-target regression tasks.

### Changed 

- The core `[ML]` package accepts modern Numpy 1.* and 2.* versions, instead of strictly requiring 2.* versions.

- ML_optimization:
    - `DragonOptimizer`, add validation for regression tasks only.

## [17.0.0] 2025-11-20

### Added

- New module: "ML_evaluation_captum", using Captum API to explain PyTorch models.
- ML_evaluation_captum:
    - `captum_feature_importance()`, calculate and visualize feature importance using Captum's Integrated Gradients.
    - `captum_image_heatmap()`, importance for image classification tasks.
    - `captum_segmentation_heatmap()`, importance for segmentation tasks.
- ML_trainer: 
    - `DragonTrainer`, added `.explain_captum()` method.
    - `DragonSequenceTrainer`, added `.explain_captum()` method.

### Changed

- ML_trainer: 
    - `DragonTrainer`, method `.explain()` renamed to `.explain_shap()`, with functionality limited to regression, binary classification and multi-class classification.

- ML_optimization:
    - `FitnessEvaluator`: Modified to handle specific target indexing for multi-target models.
    - `run_optimization()`: Added intermediate database commits inside the repetition loop to prevent data loss during long-running jobs.

- SQL:
    - `DragonSQL`: Added `commit()` method to allow manual transaction commits.

- optimization_tools:
    - `plot_optimal_feature_distributions()`: Refactored column handling to robustly exclude unoptimized targets via `target_columns` parameter.

### Fixed

- ML_optimization:
    - Fixed a serialization crash by forcing conversion of NumPy types to native Python `int`/`float` before saving to SQL or JSON.
    - Fixed an `AttributeError` in single-target regression tasks by standardizing prediction handling to support both scalar and array outputs from the inference handler.

## [16.4.0] 2025-11-19

### Changed

- ML_optimization:
    - `FitnessEvaluator`, modified to handle multi-target models.
    - `DragonOptimizer`, modified to handle multi-target models.
    - `run_optimization()`, modified to handle multi-target models.

- optimization_tools:
    - `plot_optimal_feature_distributions()`, added `ignore_columns` parameter to exclude specific columns (like unoptimized targets).

## [16.3.1] 2025-11-19

### Changed

- data_exploration: `plot_continuous_vs_target()`, migrated from legacy `numpy.polyfit` to the modern `numpy.polynomial` API internally.

## [16.3.0] 2025-11-11

### Changed

- ML_vision_datasetmaster: `DragonDatasetVision.configure_transforms()`, added the Resize transform for the train transform pipeline for consistency.

### Added

- ML_vision_transformers:
    - `LetterboxResize`, Resizes an image to fit within a target size while maintaining its aspect ratio.
    - `HistogramEqualization`, Applies histogram equalization to the image, spreading out the most frequent pixel intensity values to improve contrast.
    - `RandomHistogramEqualization`, Randomly applies histogram equalization to the image with a given probability.

## [16.2.2] 2025-11-10

### Fixed

- ML_configuration: Bugs and inconsistencies.

## [16.2.1] 2025-11-09

- Cosmetic update: Better format defaults for Configuration class in "ML_configuration" and classification_metrics in "ML_evaluation".

## [16.2.0] 2025-11-09

### Changed

- ML_configuration: Standardized format configuration for metrics according to the task:
    `RegressionMetricsFormat`
    `MultiTargetRegressionMetricsFormat`
    `BinaryClassificationMetricsFormat`
    `MultiClassClassificationMetricsFormat`
    `BinaryImageClassificationMetricsFormat`
    `MultiClassImageClassificationMetricsFormat`
    `MultiLabelBinaryClassificationMetricsFormat`
    `BinarySegmentationMetricsFormat`
    `MultiClassSegmentationMetricsFormat`
    `SequenceValueMetricsFormat`
    `SequenceSequenceMetricsFormat`
- Updated the following modules to use new format configuration classes:
    - ML_evaluation
    - ML_evaluation_multi
    - ML_sequence_evaluation
    - ML_vision_evaluation
    - ML_trainer

## [16.1.0] 2025-11-08

### Added

- ML_configuration: Metadata classes to use with "ML_trainer" classes.
- ML_inference: `DragonInference.set_target_ids()`, to manually set target ids.

### Changed

- ML_evaluation: `classification_metrics()`, takes a 'class_map' to parse label names.
- ML_Datasetmaster: `DragonDataset`, propagates the class mapping attribute to train, validation, and test datasets.
- ML_vision_datasetmaster: `DragonDatasetVision`, propagates the class mapping attribute to train, validation, and test datasets.
- ML_vision_inference: `DragonVisionInferenceHandler`, Object Detection tasks no longer use a class map for outputs. Class maps are for reference only.
- ML_trainer:
    - `DragonTrainer.explain()`, uses a memory efficient sampler. 
    - `DragonTrainer.evaluate()`, automatically finds class mappings in the dataset.
    - `finalize_model_training()`, enhanced logic and robustness for all trainer classes by requiring a configuration class.
- ML_inference: 
    - `DragonInference`, parses target names and set target ids from the model file at initialization.
    - `DragonInference`, removed `target_ids` parameter for initialization.

## [16.0.0] 2025-11-07

### Added

- New module: "ML_sequence_datasetmaster"
- New module: "ML_sequence_evaluation"
    - `sequence_to_value_metrics`
    - `sequence_to_sequence_metrics`
- New module: "ML_sequence_inference"
    - `DragonSequenceInferenceHandler`
- New module: "ML_sequence_models"
- ML_trainer: 
    - `DragonSequenceTrainer`, Supports Sequence-to-Sequence and Sequence-to-Value model training.
    - `DragonTrainer.evaluate()`, supports an optional test-set format configuration for metric output.
    - `DragonTrainer.finalize_model_training()`, saves additional artifacts for classification-related tasks.
- ML_configuration: 
    - `SegmentationMetricsFormat`
    - `SequenceValueMetricsFormat`
    - `SequenceSequenceMetricsFormat`

### Changed

- ML_datasetmaster:
    - `DragonDataset`, supports "class_map" for targets.
    - `DragonDatasetSequence`, revamped and moved to "ML_sequence_datasetmaster" module.
- ML_inference: `DragonInferenceHandler`, supports class to index conversion to get label names.
- ML_models: `DragonSequenceLSTM`, revamped and moved to "ML_sequence_models".
- ML_vision_inference: `DragonVisionInferenceHandler`, refactored and enhanced robustness.

### Deleted

- RNN_forecast: functionality included in `DragonSequenceInferenceHandler`.

## [15.1.0] 2025-11-06

### Added

- ML_evaluation: `classification_metrics()`, Optimal Classification Threshold (Youden's J Statistic) calculation.
- ML_evaluation_multi: `multi_label_classification_metrics()`, Optimal Classification Threshold (Youden's J Statistic) calculation.

### Changed

- ML_trainer: 
    - `DragonTrainer`, enhanced `.evaluate()` method for automation and robustness.
    - `DragonDetectionTrainer`, enhanced `.evaluate()` method for automation and robustness.
- ML_vision_datasetmaster: `DragonDatasetVision.configure_transforms()`, added default `RandomRotation(90)` to the train transform pipeline.
- ML_datasetmaster: Enhance all classes to support train, validation, and test dataset splits.

## [15.0.0] 2025-11-06

### Added

- ML_configuration:
    - `RegressionMetricsFormat`, Optional configuration for single-target regression and multi-target regression tasks.
    - `SegmentationMetricsFormat`, Optional configuration for segmentation tasks.

### Changed

- ML_vision_evaluation: `segmentation_metrics()`, accepts its own configuration class for formatting.
- ML_scaler: `PytorchScaler` renamed to `DragonScaler`.
- ML_optimization: `MLOptimizer` renamed to `DragonOptimizer`.
- path_manager: `PathManager` renamed to `DragonPathManager`.
- MICE_imputation: `MiceImputer` renamed to `DragonMICE`.
- SQL: `DatabaseManager` renamed to `DragonSQL`.
- ensemble_inference: `InferenceHandler` renamed to `DragonEnsembleInferenceHandler`.
- ETL_cleaning: renamed classes:
    - `DragonColumnCleaner`
    - `DragonDataFrameCleaner`
- ETL_engineering: renamed classes:
    - `DragonTransformRecipe`
    - `DragonProcessor`
- GUI_tools: renamed classes:
    - `DragonGUIConfig` 
    - `DragonGUIFactory`
    - `DragonFeatureMaster`
    - `DragonGUIHandler` 
- ML_vision_inference:
    - `PytorchVisionInferenceHandler` renamed to `DragonVisionInferenceHandler`,
    - `DragonVisionInferenceHandler`, added `predict_from_pil` method. Revamped whole structure for compatibility of standardized tasks.
- ML_inference: 
    - `PyTorchInferenceHandler` renamed to `DragonInferenceHandler`.
    - `DragonInferenceHandler`, functionality updated to handle single-target and multi-target tasks. Added `set_classification_threshold()` for binary-related tasks.
- ML_callbacks: callback classes renamed to:
    - `DragonEarlyStopping` 
    - `DragonModelCheckpoint`, functionality updated to match updated ML_trainer module.
    - `DragonLRScheduler`, saves learning rate history logs for plotting.
- ML_trainer:
    - Full revamp to enhance compatibility with callbacks and evaluation functions. 
    - Added `finalize_model_training()` method to save the final weights of the trained model ready for inference.
    - `MLTrainer` renamed to `DragonTrainer`.
    - `ObjectDetectionTrainer` renamed to `DragonDetectionTrainer`.
- ML_evaluation:
    - `plot_losses()`, added support to plot learning rate history. 
    - `classification_metrics()`, accepts its own configuration class for formatting.
    - `regression_metrics()`, accepts its own configuration class for formatting.
- ML_evaluation_multi:
    - `multi_target_regression_metrics()`, accepts its own configuration class for formatting.
    - `multi_label_classification_metrics()`, accepts its own configuration class for formatting.
- ML_datasetmaster: classes renamed:
    - `DragonDataset`, added compatibility with new tasks.
    - `DragonDatasetMulti`, added compatibility with new tasks.
    - `DragonDatasetSequence`
- ML_vision_datasetmaster: classes renamed:
    - `DragonDatasetVision`
    - `DragonDatasetSegmentation`
    - `DragonDatasetObjectDetection`
- ML_models: classes renamed:
    - `DragonMLP`
    - `DragonAttentionMLP`
    - `DragonMultiHeadAttentionNet`
    - `DragonTabularTransformer`
    - `DragonSequenceLSTM`

### Deleted

- ML_inference: `PyTorchInferenceHandlerMulti`, functionality merged into the `DragonInferenceHandler` class.

## [14.8.1] 2025-11-04

### Fixed

- ML_vision_datasetmaster: `.images_per_dataset()` returns a string without new line character.

## [14.8.0] 2025-11-04

### Added

- ML_vision_datasetmaster: 
    - `VisionDatasetMaker.images_per_dataset()`, Get the number of images per dataset as a string.
    - `SegmentationDatasetMaker.images_per_dataset()`, Get the number of images per dataset as a string.
    - `ObjectDetectionDatasetMaker.images_per_dataset()`, Get the number of images per dataset as a string.

## [14.7.0] 2025-11-04

### Changed

- ML_evaluation: `classification_metrics()`, support for plotting multiclass classification tasks.

## [14.6.0] 2025-11-04

### Changed

- ML_evaluation: `classification_metrics()`, enhanced plot outputs.
- ML_evaluation_multi: `multi_label_classification_metrics()`, enhanced plot outputs.
- ensemble_evaluation: `plot_calibration_curve()`, enhanced plot outputs.
- ML_trainer: `MLTrainer.evaluate()`, compatibility added for configuration classes.

### Added

- ML_vision_transformers: `create_offline_augmentations()`, Reads images from an input directory, applies augmentations, and saves the new images to an output directory.
- New Module: "ML_configuration", to store configuration classes.
- ML_configuration:
    - `ClassificationMetricsFormat`, optional configuration for classification tasks, use in the '.evaluate()' method of the MLTrainer.
    - `MultiClassificationMetricsFormat`, optional configuration for multi-label classification tasks, use in the '.evaluate()' method of the MLTrainer.

## [14.5.0] 2025-11-03

### Fixed

- ML_vision_datasetmaster: `SegmentationDatasetMaker` and `ObjectDetectionDatasetMaker` correctly handle optional normalization transformation when the mean and std are None.
- ML_vision_transformers: `ResizeAspectFill`, fixed attribute needed for re-creation.

### Added

- ML_datasetmaster: All classes implement a comprehensive `__repr__` method.
- ML_vision_datasetmaster: All classes implement a comprehensive `__repr__` method.

## [14.4.0] 2025-11-03

### Fixed

- ML_vision_models: All models properly store the transformation object if initialized with pretrained weights.

### Added

- ML_utilities: `save_pretrained_transforms()`, serializes the transform object of pretrained models as a .joblib file.

## [14.3.1] 2025-11-03

### Fixed

- ML_vision_datasetmaster: `VisionDatasetMaker.save_transform_recipe()`, now uses introspect to save default Torchvision transformations and possibly other custom transformations in the recipe.

## [14.3.0] 2025-11-03

### Added

- ML_vision_datasetmaster: `VisionDatasetMaker.save_class_map()`, saves the class to index map to a JSON file. 

## [14.2.2] 2025-11-03

### Fixed

- ML_vision_datasetmaster: `VisionDatasetMaker`, the methods to initialize an instance correctly handle Path objects.

## [14.2.1] 2025-11-03

### Changed

- ML_vision_datasetmaster: `VisionDatasetMaker`, correctly handles optional normalization transformation when the mean and std are None.

## [14.2.0] 2025-11-02

### Added

- New optional dependencies `pytorch_tabular`, and `omegaconf`. Required for the module "ML_models_advanced".
- Updated third-party licenses.
- ML_models_advanced: 
    - `DragonGateModel`, Adapter for the Gated Additive Tree Ensemble (GATE) model from the 'pytorch_tabular' library.
    - `DragonNodeModel`, Adapter for the Neural Oblivious Decision Ensembles (NODE) model from the 'pytorch_tabular' library.

## [14.1.0] 2025-11-02

### Changed

- data_exploration: `plot_value_distributions()`, new enhanced plotting logic.

### Added

- data_exploration:
    - `plot_continuous_vs_target`, Plots each continuous feature against each target to visualize linear relationships.
    - `plot_categorical_vs_target`, Plots each categorical feature against each numeric target using box or violin plots.

## [14.0.0] 2025-11-01

### Changed

- ML_trainer: `MLTrainer`, modified logic to handle segmentation tasks.
- custom_logger: `custom_logger()`, adding a timestamp to the log is optional.
- ML_datasetmaster: 
    - `VisionDatasetMaker`, revamped to improve conciseness. Supports loading images from a single directory or several directories. Moved to "ML_vision_datasetmaster"
    - `ResizeAspectFill`, moved to "ML_vision_transformers"

### Added

- New project dependency: `torchmetrics`
- New module: "ML_vision_transformers"
- New module: "ML_vision_evaluation"
- New module: "ML_vision_models"
- New module: "ML_vision_inference"
- New Module: "ML_vision_datasetmaster"
- ML_utilities: `inspect_model_architecture()`, Saves a human-readable text summary of a model's instantiated architecture, including parameter counts.
- ML_trainer: `ObjectDetectionTrainer`, Automates the training process of an Object Detection Model
- ML_vision_inference: `PyTorchVisionInferenceHandler`, Handles loading a PyTorch vision model's state dictionary and performing inference.
- ML_vision_datasetmaster: 
    - `SegmentationDatasetMaker`, Creates processed PyTorch datasets for segmentation from image and mask folders.
    - `ObjectDetectionDatasetMaker`, Creates processed PyTorch datasets for object detection from image and JSON annotation folders.
- ML_vision_evaluation:
    - `segmentation_metrics()`, Calculates and saves pixel-level metrics for segmentation tasks.
    - `object_detection_metrics()`, Calculates and saves object detection metrics (mAP) using the torchmetrics library.
- ML_vision_models:
    - `DragonResNet`, A customizable wrapper for the torchvision ResNet family.
    - `DragonEfficientNet`, A customizable wrapper for the torchvision EfficientNet family.
    - `DragonVGG`, A customizable wrapper for the torchvision DragonVGG family.
    - `DragonFCN`, A customizable wrapper for the torchvision FCN family.
    - `DragonDeepLabv3`, A customizable wrapper for the torchvision DeepLabv3 family.
    - `DragonFastRCNN`, A customizable wrapper for the torchvision Faster RCNN family.

## [13.8.0] 2025-10-31

### Changed

- custom_logger: `custom_logger()`, new parameter to enforce dictionary output as JSON or CSV.

### Added

- ML_utilities:
    - `get_model_parameters()`, calculates the total and trainable parameters of a PyTorch model.
    - `inspect_pth_file()`, inspects a .pth file (e.g., checkpoint) and saves a human-readable JSON summary of its contents.
    - `set_parameter_requires_grad()`, freezes or unfreezes parameters in a model.

## [13.7.0] 2025-10-30

### Added

- MICE_imputation: `MiceImputer`, a modern MICE imputation pipeline that uses a FeatureSchema to correctly discretize categorical features after imputation.
- utilities:
    - `save_dataframe_with_schema()`, saves a Pandas Dataframe into a CSV file, strictly validating its feature columns against a FeatureSchema.
    - `load_dataframe_with_schema()`, loads a CSV file into a Pandas DataFrame, strictly validating its feature columns against a FeatureSchema.

## [13.6.0] 2025-10-30

### Changed

- utilities:
    - `save_dataframe_filename()`, converts empty strings to None before saving the CSV file.
    - `load_dataframe()`, loads empty strings as None values.

## [13.5.0] 2025-10-30

### Changed

- ML_evaluation: `shap_summary_plot()`, fix a numpy shape error for plotting values. Set default explainer to KernelExplainer for better compatibility with all models.
- ML_evaluation_multi: `multi_target_shap_summary_plot()`, Set default explainer to KernelExplainer for better compatibility with all models.
- ML_trainer: `MLTrainer.explain_attention()`, will attempt to obtain feature names from the dataset if not explicitly provided.

## [13.4.0] 2025-10-29

### Changed

- ML_datasetmaster: `DatasetMaker` and `DatasetMakerMulti`'s parameter `scaler` now must be explicitly provided with the options "fit", "none", or a `ML_scaler.PytorchScaler` instance.

## [13.3.2] 2025-10-29

### Fixed

- math_utilities: `discretize_categorical_values()`, fixed bug in the implementation.

### Changed

- ML_models: `TabularTransformer` default parameter values adjusted. Added description.

## [13.3.1] 2025-10-29

### Fixed

- serde: Serialization and Deserialization functions will log the type() if it is a common type or the object if it is not. 

## [13.3.0] 2025-10-29

### Added

- `FeatureSchema`: implemented __repr__ for clean logging.

### Changed

- serde: 
    - Serialization and Deserialization functions will log the type() if it is a common type or the object if it is not. 
    - Added a guard that fails early when attempting to save None objects.

## [13.2.1] 2025-10-29

### Added

- `FeatureSchema`: `save_artifacts()`, wrapper to save all feature names, continuous feature names, and categorical feature names to separate text files.

### Changed

- `FeatureSchema`: The save methods will fail with a warning if the value is empty.

## [13.2.0] 2025-10-29

### Added

- `FeatureSchema` can directly be called from main module as `from ml_tools import FeatureSchema`
- `FeatureSchema`:
    - `save_all_features()`, Saves all feature names to a text file.
    - `save_continuous_features()`, Saves continuous feature names to a text file.
    - `save_categorical_features()`, Saves categorical feature names to a text file.

- serde:
    - `serialize_schema`, serializes a `FeatureSchema` object to a .joblib file.
    - `deserialize_schema`, deserializes a `FeatureSchema` object from a .joblib file.

## [13.1.0] 2025-10-28

### Added

- data_exploration: `finalize_feature_schema()`, Analyzes the final features DataFrame to create a definitive "single source of truth" for column order and type (categorical vs. continuous) for the entire ML pipeline. Returns a `FeatureSchema` NamedTuple instance.

### Changed

- ML_models: `TabularTransformer`, overhauled to make use of a `FeatureSchema` instance.
- optimization_tools: `create_optimization_bounds()`, overhauled to make use of a `FeatureSchema` instance.
- ML_optimization: `MLOptimizer`, overhauled to make use of a `FeatureSchema` instance. Automatically uses `create_optimization_bounds()` under the hood.
- ML_datasetmaster: `DatasetMakerMulti`, `DatasetMaker`, overhauled to make use of a `FeatureSchema` instance.

### Removed

- data_exploration: `create_transformer_categorical_map()` in favor of the `FeatureSchema` class implementation.
- Module: "ML_simple_optimization", incompatible with new robust pipeline.
- Jupyter notebook examples, outdated.

### Deprecated

- PSO_optimization: legacy module for simple optimizations using ensemble models.

## [13.0.0] 2025-10-28

### Added

- ML_trainer: 
    - `MLTrainer.to_cpu()`, moves the model to the CPU and updates the trainer's device setting.
    - `MLTrainer.to_device()`, moves the model to the specified device and updates the trainer's device setting.

### Changed

- ML_trainer: `MLTrainer.fit()`, allows training to be resumed from a previously saved checkpoint.
- ML_callbacks: `ModelCheckpoint`, Now saves a comprehensive training checkpoint as a dictionary including model state, optimizer state, LR scheduler, epoch, and best score.
- ML_inference: Inference Handler classes updated to be backward-compatible and also use the new comprehensive checkpoints.

### Fixed

- ML_evaluation_multi, ML_evaluation: Ignore UserWarning when using SHAP Deep Explainer.

## [12.13.0] 2025-10-28

### Changed

- ML_evaluation_multi, ML_evaluation: Changed the default SHAP explainer from KernelExplainer to DeepExplainer. SHAP explanations will now run on the provided `torch.device`.
- ML_trainer: `MLTrainer.explain()`, updated to reflect the changes on the SHAP explanation functions.

## [12.12.0] 2025-10-27

### Changed

- ML_datasetmaster: Parameter "save_dir" renamed to "directory" for consistency in the method `save_scaler()`. Affecting the classes `DatasetMaker` and `DatasetMakerMulti`.
- ML_models: `TabularTransformer`'s parameter "categorical_map" renamed to "categorical_index_map" for clarity.
- ML_callbacks: Enhanced docstring for callback classes: `ModelCheckpoint`, `EarlyStopping`, and `LRScheduler`.

### Added

- ML_datasetmaster: 
    - `DatasetMaker` and `DatasetMakerMulti`:
        - New method `save_artifacts()`, saves feature names, target names, and scaler if any.
        - New methods as properties: `number_of_features`, `number_of_targets`. 

## [12.11.0] 2025-10-27

### Changed

- serde: `deserialize_object()`, will always raise an exception in case of an error.

## [12.10.0] 2025-10-24

### Added

- custom_logger: `compare_lists()`, compares two lists and saves a JSON report of the differences.

## [12.9.2] 2025-10-24

### Changed

- data_exploration: `reconstruct_one_hot()`, the baseline category name can also be set to None. Default is still "Other".

## [12.9.1] 2025-10-24

### Changed

- data_exploration: `reconstruct_one_hot()`, the baseline category name can be passed, it defaults to "Other".

## [12.9.0] 2025-10-24

### Changed

- data_exploration: 
    - `encode_categorical_features()`, the function now safely handles null-label collisions when encode_nulls=True.
    - `reconstruct_one_hot()`, The function signature has been fundamentally changed to support the reversal of drop_first=True (baseline) encodings.

## [12.8.0] 2025-10-23

### Changed

- ML_utilities: `select_features_by_shap()`, added option to save resulting feature names as a txt file to a directory.
- optimization_tools: `create_optimization_bounds()`, continuous column names provided but not found in the dataset will be skipped with a warning instead of raising an error.

## [12.7.0] 2025-10-23

### Added

- utilities: `load_dataframe_greedy()`, greedily loads the first found CSV file from a directory into a Pandas DataFrame.

## [12.6.0] 2025-10-23

### Changed

- utilities: 
    - `save_dataframe()`, renamed to `save_dataframe_filename()` to better reflect that it constructs the output path from a separate directory and filename.
    - `save_dataframe_path()`, renamed to `save_dataframe()`, saves a dataframe directly to a path.

### Fixed

- Use the correct form of helper functions in all scripts.

## [12.5.0] 2025-10-23

### Changed

- serde: `serialize_object()`, renamed to `serialize_object_filename()` to better reflect that it constructs the output path from a separate directory and filename.

### Added

- serde: `serialize_object()`, serializes a Python object using joblib to a specific file path.

## [12.4.0] 2025-10-23

### Changed

- data_exploration: `standardize_percentages()`, added a verbose parameter to print the names of columns standardized.

## [12.3.0] 2025-10-21

### Added

- ML_optimization: `FitnessEvaluator`, handles the on-the-fly discretization of categorical features serving as a fitness function.

### Changed 

- ML_optimization: 
    - `MLOptimizer` class refactored to instantiate and use the new `FitnessEvaluator`, separating the evaluation logic from the optimization setup.
    - `create_pytorch_problem` function refactored to accept a `FitnessEvaluator` instance instead of a `PyTorchInferenceHandler`. 

## [12.2.0] 2025-10-20

### Added

- data_exploration: `reconstruct_binary()`, reconstructs new categorical columns from existing binary (0/1) columns.
- optimization_tools: `create_optimization_bounds()`, support for UTF-8 characters in CSV files.

## [12.1.0] 2025-10-20

### Added

- data_exploration: `drop_outlier_samples()`, for dropping outlier samples (rows) from a DataFrame.
- optimization_tools: `create_optimization_bounds()`, generates the lower and upper bounds lists for the ML optimizer.

### Changed 

- math_utilities: `discretize_categorical_value()`, support for 1D arrays added.
- ML_optimization: 
    - Brand new algorithm logic to handle categorical features properly.
    - Old implementations renamed to "ML_simple_optimization", useful when there is only binary features and no one-hot or other categorical features. Deprecated.
- optimization_tools: `plot_optimal_feature_distributions()`, modified to support new categorical handling.

## [12.0.1] 2025-10-18

- Minor fix for conda-forge release.

## [12.0.0] 2025-10-17

### Changed

- Recommended Python version 3.12.
- ensemble_learning: `run_ensemble_pipeline()`, the model will be saved by default.
- data_exploration: `plot_correlation_heatmap()`, the plot title must be explicitly defined, automatic suffix added.
- ETL_engineering: `AutoDummifier`, no longer returns '_null' category columns.
- utilities: 
    - `select_features_by_shap()`, the SHAP value threshold must be explicitly defined.
    - `normalize_mixed_list()`, moved to module "math_utilities".
    - `threshold_binary_values()`, moved to module "math_utilities".
    - `threshold_binary_values_batch()`, moved to module "math_utilities".
    - `find_model_artifacts()`, moved to module "ML_utilities".
    - `select_features_by_shap()`, moved to module "ML_utilities".
    - `serialize_object()`, moved to module "serde".
    - `deserialize_object()`, moved to module "serde".

### Added

- New module: "ML_utilities"
- New module: "serde"
- New module: "math_utilities"
- math_utilities: `discretize_categorical_value()`, rounds specified columns of a 2D NumPy array to the nearest integer and clamps the result to a valid categorical range.
- utilities: `save_dataframe_path()`, convenience wrapper for `save_dataframe()` using a single Path object.

### Removed

- Optional dependency: Base CPU installation of PyTorch.
- Optional dependency: independent installation of matplotlib and seaborn.

## [11.1.1] 2025-10-17

### Fixed

- ETL_engineering: `MultiNumberExtractor`, fix bug when parsing non-existent numbers.

## [11.1.0] 2025-10-17

### Changed

- ETL_engineering: Standardize output column names of transformer classes returning a DataFrame to better work with the `DataProcessor` pipeline.
- ETL_cleaning: `save_unique_values()`, preserves original column order in the output filenames by default.

## [11.0.0] 2025-10-16

### Changed

- ETL_engineering: 
    - `TransformationRecipe`, the parameters `output_col_names()` is now optional. If None, the column names will be the same as returned by the transformer (DataFrame) or as the original input name (Series).
    - `DataProcessor`, can add a common prefix to the outputs of any transformer.

### Added

- New Module: 'constants', general purpose STEM constants.

- ETL_cleaning: 
    - Enhanced cleaning regex strategy for base cleaner functions.
    - `save_unique_values()`, new optional parameter to preserve original column order in the output filenames.

- ETL_engineering: `MolecularFormulaTransformer`, parses a Polars Series of molecular formula strings into a wide DataFrame.

## [10.15.0] 2025-10-13

### Added

- ML_optimization: `MLOptimizer`, a wrapper class for setting up and running EvoTorch optimization tasks.

## [10.14.0] 2025-10-13

### Changed

- ETL_cleaning: 
    - Enhanced cleaning regex strategy for base cleaner functions.
    - `basic_clean_drop()` and `basic_clean()` now include the parameter `all_lowercase` that controls whether all values should be normalized to lowercase in the cleaning process.

## [10.13.0] 2025-10-13

### Added

- Add dependency `pyarrow` for the core project modules: "Machine Learning" and "MICE". Dependency required for ETL_cleaning.

### Removed

- Removed the core project module "Base".

## [10.12.1] 2025-10-13

### Changed

- ETL_cleaning: enhanced cleaning regex strategy for base cleaner functions.

## [10.12.0] 2025-10-13

### Changed

- ML_models: `TabularTransformer`, API has been simplified and made more robust. It now accepts an 'in_features' argument instead of 'numerical_indices'.

### Added

- data_exploration:
    - `encode_categorical_features()`, automates the label encoding of specified categorical columns and returns a dictionary containing their mappings.
    - `create_transformer_categorical_map()`, generates the 'categorical_map' required by the 'TabularTransformer' model.
    - `reconstruct_one_hot()`, function to collapse one-hot encoded columns back into a single categorical feature.

## [10.11.2] 2025-10-12

### Fixed

- path_manager: `PathManager.__setattr__` fixed and working.

## [10.11.1] 2025-10-11

### Changed

- utilities: `deserialize_object()`, added runtime type validation. The function signature was updated using typing.TypeVar for improved static typing.

## [10.11.0] 2025-10-11

### Changed

- path_manager: `PathManager` now supports direct attribute access for all paths, providing a cleaner, safer, and more modern way to interact with class instances.

## [10.10.1] 2025-10-10

### Fixed

- SQL: `DatabaseManager`, fixed bug with table names. Now all methods use a sanitized string version of the input table name.

## [10.10.0] 2025-10-10

### Changed

- ML_models: Attention-related models now have the attribute `has_interpretable_attention`, to check if the attention mechanism can be interpreted.
- ML_trainer: `MLTrainer.explain_attention()`, checks if the model attention is compatible before executing.

### Added

- ML_evaluation: `plot_attention_importance()`, added a parameter to control the number of features to be plotted.

## [10.9.0] 2025-10-07

### Changed

- ensemble_evaluation: `get_shap_values()` now saves a SHAP summary as a csv file.
- SQL: `DatabaseManager`, sanitizes the table name before creation.
- utilities: `load_dataframe()`, supports loading all columns or a subset of columns.

### Added

- utilities: `select_features_by_shap()`, scans subdirectories to find SHAP summary CSVs, then extracts feature names whose mean absolute SHAP value meets a specified threshold.

## [10.8.0] 2025-10-07

### Added

- path_manager: `list_subdirectories()`, scans a directory and returns a dictionary of its immediate subdirectories.
- utilities: `find_model_artifacts`, scans trained model directories to find paths to model weights, scalers, model architecture, feature names, and target names.
- ML_datasetmaster: `DatasetMaker` and `DatasetMakerMulti` now return and/or save a list of target names with the attribute `.target_names` and method `save_target_names()`.
- ML_scaler: `PytorchScaler`, added 'verbose' parameters to some methods.

## [10.7.0] 2025-10-07

### Fixed

- ML_datasetmaster: internal training and test datasets based on `_PytorchDataset` will correctly inherit the feature names and target names from the classes using them.
- ML_trainer: `MLTrainer.explain()` correctly handles Datasets with feature names and target names as needed.
- ML_scaler: `PytorchScaler.save()` properly handles filepaths.

## [10.6.0] 2025-10-07

### Added

- ML_models: Added methods to the model classes:
    - `.save()`, saves the model's architecture to an JSON file.
    - `.load()`, loads a model architecture from a JSON file or a directory containing a JSON file.

### Removed

- ML_models:
    - `load_architecture()`, use model method instead.
    - `save_architecture()`, use model method instead.

## [10.5.0] 2025-10-07

### Added

- data_exploration: `clean_column_names()`, cleans DataFrame column names by replacing special characters.

## [10.4.2] 2025-10-07

### Fixed

- ETL_engineering: `TemperatureExtractor`, bug when using the average_mode.

## [10.4.1] 2025-10-06

### Fixed

- ETL_engineering: 
    - `MultiTemperatureExtractor`, bug with lazy evaluation of Null values.
    - `TriRatioCalculator`, bug with lazy evaluation of Null values.

## [10.4.0] 2025-10-06

### Added

- ETL_engineering: 
    - `TemperatureExtractor`, extracts temperature values from a string column.
    - `MultiTemperatureExtractor`, extracts multiple temperature values from a single string column into several new columns.
    - `AutoDummifier`, now has an optional 'drop_first' parameter.

## [10.3.0] 2025-10-05

### Added

- ETL_engineering:
    - `DataProcessor.load_transform_save()`, convenience wrapper for the transform method that includes automatic dataframe loading and saving.
    - `RatioCalculator`, includes optional handling for zeros and single numbers.
    - `TriRatioCalculator`, A transformer that handles three-part ("A:B:C") and two-part ("A:C") mixed ratios.

## [10.2.1] 2025-10-04

### Added

- ETL_cleaning: expanded regex rules for basic data cleaners.

## [10.2.0] 2025-10-04

### Added

- ETL_cleaning: `basic_clean_drop()`, combines `basic_clean()` and `drop_macro()` (from the "data_exploration" module).

## [10.1.1] 2025-10-03

### Added

- ETL_cleaning: `save_unique_values()` now has a verbose parameter.

## [10.1.0] 2025-10-03

### Changed

- ETL_cleaning:
    - `basic_clean()`, expanded full-width character cleaning.
    - `ColumnCleaner`, no longer performs regex pattern validation using an incompatible engine.

## [10.0.1] 2025-10-01

### Fixed

- ETL_cleaning: minor logging tweaks.

## [10.0.0] 2025-10-01

### Added

- New module: ETL_cleaning
- ETL_cleaning: `basic_clean()`, performs a comprehensive, standardized cleaning on all columns of a CSV file.

### Changed

- Moved from "ETL_engineering" to "ETL_cleaning":
    - `save_unique_values()`
    - `ColumnCleaner`
    - `DataFrameCleaner`

## [9.2.0] 2025-09-30

### Added 

- ETL_engineering: 
    - `DataFrameCleaner` and `ColumnCleaner` can now handle cleaning of values to 'None'. 
    - `DataFrameCleaner.clean()`, added the option to work on a clone of the dataframe.
    - `DataFrameCleaner.load_clean_save()`, convenient wrapper that encapsulates the entire cleaning process into a single call.

## [9.1.0] 2025-09-29 

### Changed

- ETL_engineering: `save_unique_values()`, reduce log output to avoid cluttering the terminal.
- handle_excel: `validate_excel_schema()`, now displays the cause(s) of any problem found.

## [9.0.0] 2025-09-28

### Added

- New optional dependency "colorlog" library for enhanced log visualizations.
- ETL_engineering: `save_unique_values()`, Loads a CSV file, then analyzes it and saves the unique non-null values from each column into separate text files.

### Changed

- Visualization change to the package's logger output in all modules.

## [8.2.0] 2025-09-26

### Added

- ETL_engineering: `AutoDummifier`, A transformer that performs one-hot encoding on a categorical column.

## [8.1.0] 2025-08-19

### Added

- data_exploration: `drop_macro()`, iteratively removes rows and columns with excessive missing data.

## [8.0.0] 2025-08-09

### Added

- ML_datasetmaster: `DatasetMakerMulti`, handle multi-target regression or multi-label-binary classification tasks.
- ML_inference: 
    - `PyTorchInferenceHandlerMulti`, handle multi-target regression or multi-label-binary classification tasks.
    - `PyTorchInferenceHandler`, added method `quick_predict()`, convenience wrapper to get a mapping {target_name: prediction/label} for regression and classification.
- ML_evaluation_multi: New module that contains metric-evaluation functions for multi-target regression or multi-label-binary classification tasks.:
    - `multi_target_regression_metrics()`
    - `multi_label_classification_metrics()`
    - `multi_target_shap_summary_plot()`

### Changed

- ML_trainer: Updated logic to work with multi-target regression or multi-label-binary classification tasks.

## [7.0.0] 2025-08-07

### Added

- ML_models: 
    - `AttentionMLP`, A Multilayer Perceptron that incorporates an Attention layer to dynamically weigh input features.
    - `MultiHeadAttentionMLP`, A Multilayer Perceptron that incorporates a MultiheadAttention layer to process the input features.
    - `TabularTransformer`,  A Transformer-based model for tabular data tasks.
- ML_scaler: `PytorchScaler`, Standardizes continuous features in a PyTorch dataset by subtracting the mean and dividing by the standard deviation.
- ML_evaluation: `plot_attention_importance()`, Aggregates attention weights and plots global feature importance.
- ML_trainer: `MLTrainer.explain_attention()`, Automates the generation of a feature importance plot based on attention weights.

### Removed

- ML_datasetmaster: Original `DatasetMaker`, deprecated functionality.

### Changed

- ML_evaluation: `shap_summary_plot()`, "save directory" is no longer optional.
- ML_trainer: `MLTrainer.explain()`, modified parameters to match new SHAP functionality.
- ML_datasetmaster: 
    - `SimpleDatasetMaker` renamed to `DatasetMaker`.
    - `DatasetMaker` automates the creation and usage of a `PytorchScaler`.
    - `SequenceMaker` makes use of the `PytorchScaler` instead of Scikit-learn's scaler.

## [6.4.1] 2025-08-06

### Fixed

- ML_inference: `multi_inference_regression()` and `multi_inference_classification()` return python float instead of numpy float for single vector inference.

## [6.4.0] 2025-08-06

### Added

- ML_inference: `multi_inference_regression()` and `multi_inference_classification()`, perform inference using multiple models on a single feature vector.

## [6.3.0] 2025-08-05

### Added

- ML_inference: `PyTorchInferenceHandler`, optional "target_id" attribute.
- ML_models: `save_architecture()` and `load_architecture()` for pytorch models implementing the method `get_config()`.
- custom_logger: `save_list_strings()` and `load_list_strings()` save and load a list of strings to and from a text file.
- ML_datasetmaster: `DatasetMaker` and `SimpleDatasetMaker` can save feature names as text files using the `save_feature_names()` method.

## [6.2.1] 2025-08-01

### Fixed 

- ML_callbacks: `ModelCheckpoint` sanitize filename before using it.

## [6.2.0] 2025-08-01

### Changed

- ML_optimization: Better default values for operators of the Genetic Algorithm to encourage exploration.
- ML_callbacks: `ModelCheckpoint` now accepts an optional checkpoint filename.
- optimization_tools: `plot_optimal_feature_distributions()` automatically generates an output subdirectory to save plots.

## [6.1.2] 2025-08-01

### Fixed

- ML_optimization: Save evolution logs with target names to prevent overwriting.

## [6.1.1] 2025-08-01

### Fixed

- ML_optimization: Make copies of boundary lists to prevent unintended changes when running multiple repetitions.

## [6.1.0] 2025-08-01

### Fixed

- ML_optimization: Make correct use of the evotorch library.

### Changed

- ML_inference: `PyTorchInferenceHandler` will use 4 methods to handle return types as numpy array or torch tensor:
    - `predict_numpy()`
    - `predict_batch_numpy()`
    - `predict()`
    - `predict_batch()`

## [6.0.1] 2025-08-01

### Fixed

- ensemble_evaluation: `plot_calibration_curve()` Fix title display.
- ML_evaluation: `shap_summary_plot()` Fix title and axis labels display.

## [6.0.0] 2025-07-31

### Added 

- ensemble_evaluation: 
    - `plot_precision_recall_curve()`, for classification models.
    - Integrated classification report heatmap into the `evaluate_model_classification()` function.
    - `plot_calibration_curve()`, reliability diagram for a classifier.
    - `plot_learning_curves()`, generates and saves a plot of the learning curves for a given estimator to diagnose bias vs. variance.
    - Integrated histogram of residuals into the `evaluate_model_regression()` function.

- ML_evaluation:
    - `classification_metrics()`
        - Save directory no longer optional.
        - Added precision-recall curve plot.
        - Added classification report heatmap.
        - Added calibration curve plot.
    - `regression_metrics()`
        - Save directory no longer optional.
        - Added histogram of residuals.

### Changed

- ensemble_learning: 
    - split into 2 modules: "ensemble_learning" and "ensemble_evaluation". 
    - `dataset_yielder()` renamed to `train_dataset_yielder()` and moved to "utilities".
- ML_trainer: 
    - `MyTrainer` renamed to `MLTrainer`.
    - method `explain()` has a new default of 'n_samples = 1000'.
- keys:
    - `LogKeys` renamed to `PyTorchLogKeys`.
    - `ModelSaveKeys` renamed to `EnsembleKeys`.

## [5.3.1] 2025-07-31

### Fixed

- ML_evaluation: `shap_summary_plot()` now works properly using a KernelExplainer for robustness.
- ML_trainer: Train set dataloader now drops the last batch if it is incomplete to prevent errors in certain situations when the last batch has only 1 sample.

## [5.3.0] 2025-07-30

### Changed

- ML_callbacks: change `np.Inf` to `np.inf`, requiring Numpy version >= 2.0.
- Fixed dependency `Numpy>=2.0` for the core Machine Learning modules.
- utilities: Use module logger instead of print.
- data_exploration: Use module logger instead of print.

### Fixed

- ML_datasetmaster, correct dtype when creating datasets for regression tasks.

## [5.2.2] 2025-07-28

### Added

- ML_models:
    - `MultilayerPerceptron` add string representation.
    - `SequencePredictorLSTM` add string representation.

## [5.2.1] 2025-07-28

### Changed

- ML_datasetmaster: `SimpleDatasetMaker` now has a default ID attribute set to None and can be manually set to any string if needed.
- ML_callbacks: Enhanced docstrings.
- ML_trainer: Enhanced docstrings.

### Fixed

- ML_optimization: `create_pytorch_problem()` the inner fitness function will correctly handle continuous and binary values.

## [5.2.0] 2025-07-28

### Added

- New module: "ML_models"
- ML_models:
    - `MultilayerPerceptron`, a versatile Multilayer Perceptron (MLP) for regression or classification tasks.
    - `SequencePredictorLSTM`, a simple LSTM-based neural network for sequence-to-sequence prediction tasks.

## [5.1.0] 2025-07-28

### Added

- ML_datasetmaster: `SimpleDatasetMaker`, a streamlined PyTorch dataset maker for pre-processed, numerical pandas DataFrames.

## [5.0.0] 2025-07-24

### Added

- New dependency: Evotorch.
- New modules:
    - "ML_optimization"
    - "optimization_tools"
- ML_optimization: Optimization algorithm to be used with PyTorch models.
    - `create_pytorch_problem()`, Creates and configures an EvoTorch Problem and Searcher.
    - `run_optimization()`, Runs the evolutionary optimization process, with support for multiple repetitions.
- optimization_tools:
    - `parse_lower_upper_bounds()`,
    - `plot_optimal_feature_distributions()`

### Changed

- PSO_optimization: `parse_lower_upper_bounds()`, `plot_optimal_feature_distributions()` moved to "optimization_tools".
- datasetmaster: renamed to "ML_datasetmaster", part of the PyTorch tools environment.

## [4.5.0] 2025-07-24

### Added

- Simplified import for `custom_logger()` as `from ml_tools import custom_logger`
- PSO_optimization: `parse_lower_upper_bounds()` to automate boundary list creation from a dictionary.

## [4.4.0] 2025-07-23

### Fixed

- data_exploration: `split_features_target()` validates target columns to prevent errors.

### Changed

- custom_logger: `custom_logger()` now has no base dependencies and can be used anywhere.

## [4.3.0] 2025-07-23

### Changed

- data_exploration:
    - `drop_rows_with_missing_data()` validates target columns before using them.
    - `drop_columns_with_missing_data()` accepts column names to be skipped from the process.

## [4.2.2] 2025-07-23

### Fixed

- ETL_engineering: `RatioCalculator` will not raise a confusing exception when handling messy data, instead it will just output 'None'.

## [4.2.1] 2025-07-23

### Fixed

- ETL_engineering: `KeywordDummifier` will properly handle expressions before trying to convert them to a Dataframe.

## [4.2.0] 2025-07-21

### Added

- path_manager: `PathManager` can now also handle Nuitka bundled applications.
- APP bundlers: Pyinstaller, Nuitka.

## [4.1.0] 2025-07-21

### Added

- New module: "SQL"
    - `DatabaseManager`, A user-friendly context manager for handling SQLite database operations.

### Changed

- PSO_optimization
    - Updated logic to save best results to a .csv directly and incrementally, instead of loading them all in memory.
    - Supports saving data to a SQL database, working with `SQL.DatabaseManager` under the hood.

## [4.0.0] 2025-07-19

### Added 

- ML_inference: `PyTorchInferenceHandler` handles inference of pytorch models.
- ensemble_inference: handles inference of boosting models.
- Example notebooks in the GitHub repository.

### Changed

- Package base dependencies removed. Install grouped dependencies for specific usage instead. Check README for more information.
- path_manager: `PathManager` supports both development mode and applications bundled with Pyinstaller.
- logger:
    - `custom_logger()`: moved to its own module "custom_logger". No longer supports logging to excel, for dependency simplicity.
    - renamed to "_logger", now only used internally.
- utilities:
    - `sanitize_filename()` moved to "path_manager".
    - `make_fullpath()` moved to "path_manager".
    - `list_csv_paths()` moved to "path_manager".
    - `list_files_by_extension()` moved to "path_manager".
- ensemble_learning:
    - Drop support for HistGB models in the factory classes.
    - `InferenceHandler` and `model_report()` moved to a new module: "ensemble_inference"

### Removed

- data_exploration: `check_value_distributions()` deleted, not useful enough to justify its extra dependencies.
- PSO_optimization: drop support for HistGB models.
- ML_tutorial: module deleted in favor of a direct usage examples shown in jupyter notebooks.

## [3.12.6] 2025-07-15

### Added

- GUI_tools: `GUIFactory` can now attempt to center layouts using "sg.Push()" elements.

## [3.12.5] 2025-07-15

### Fixed

- GUI_tools: `GUIFactory` will properly generate the desired number of columns per layout when using 'grid'.

## [3.12.4] 2025-07-15

### Fixed

- GUI_tools: `ConfigManager` incorrectly parsing color values as comments.

## [3.12.3] 2025-07-15

### Fixed

- GUI_tools: 
    - `ConfigManager` and `GUIFactory` will correctly exchange configuration details.
    - `GUIFactory.generate_continuous_layout()` will not cast range values to integers, it will use the same type as received.

## [3.12.2] 2025-07-15

### Fixed

- GUI_tools: `FeatureMaster` and `GUIHandler` will properly add and process the "other" option for one-hot-encoding.

## [3.12.1] 2025-07-15

### Added

- utilities: `sanitize_filename()` added edge case check for empty string outputs.
- utilities: `make_fullpath()` can now enforce a "directory" or "file".

### Fixed

- Standardize print outputs throughout the package.

## [3.12.0] 2025-07-14

### Added

- GUI_tools:
    - New method `generate_multiselect_layout()` for the class `GUIFactory`, generates a layout for features using Listbox elements for multiple selections.
    - `FeatureMaster` can properly handle "multi binary features"
    - `GUIHandler` can properly handle "multi binary features"

## [3.11.0] 2025-07-14

### Added

- GUI_tools: `FeatureMaster`, `GUIHandler` to fully handle GUI-model communication.

### Fixed

- ensemble_learning: `InferenceHandler` uses constant keys for classification outputs.

### Deleted

- GUI_tools: `update_target_fields()` and `BaseFeatureHandler` in favor of the new fully automated OOP approach

## [3.10.2] 2025-07-12

### Fixed

- GUI_tools: `update_target_fields()` includes a key mapping parameter to handle customized target names in the GUI.

## [3.10.1] 2025-07-12

### Fixed

- GUI_tools: `BaseFeatureHandler` 2 new methods required in order to work properly with personalized GUI names, core logic modified.

## [3.10.0] 2025-07-12

### Added

- ensemble_learning: `model_report()` Deserializes a model and generates a summary report.
- New Module: "keys" used to keep track of constant keys. Moved existing keys to module. Updated scripts to use the new location.

### Removed

- Deprecated module "_particle_swarm_optimization".

## [3.9.1] 2025-07-11

### Fixed

- GUI_tools: `GUIFactory.generate_continuous_layout()` fix None value handling, raise ValueError if not used properly.

## [3.9.0] 2025-07-11

### Added

- ensemble_learning: `InferenceHandler` Handles loading ensemble models and performing inference for either regression or classification tasks.
- GUI_tools: `BaseFeatureHandler` An abstract base class that defines the template for preparing a model input feature vector to perform inference, from GUI inputs.
- New Module: "path_manager" with the class `PathManager` Manages and stores a project's file paths, acting as a centralized path database. Supports dictionary-like syntax.

### Changed

- GUI_tools: `prepare_feature_vector()` deleted in favor of the new class `BaseFeatureHandler`.
- utilities: `PathManager` moved to its own module.

## [3.8.0] 2025-07-11

### Fixed

- GUI_tools: Fix parameter names and docstrings to better explain how each class and function works.

### Changed

- GUI_tools: `PathManager` moved to "utilities".
- utilities: `PathManager` Manages and stores a project's file paths, acting as a centralized path database. Supports dictionary-like syntax.

## [3.7.0] 2025-07-10

### Fixed

- data_exploration: `drop_constant_columns()` verbose will correctly work even if no columns were processed.
- PSO_optimization: `plot_optimal_feature_distributions()` revamped due to many problems found in the previous implementation. 
- Quality of life enhancements when printing messages.

### Changed

- GUI_tools: `update_target_fields()` now expects the complete target key string, to avoid issues when using custom keys.

## [3.6.0] 2025-07-09

### Changed

- data_exploration: `drop_zero_only_columns()` changed to `drop_constant_columns()` a more useful version useful for removing constant features that have no predictive value.

## [3.5.1] 2025-07-09

### Fixed

- ETL_engineering: Fixed a bug in `KeywordDummifier` trying to use DataFrame constructor with a polars expression.
- data_exploration: Fixed a bug in `drop_zero_only_columns()` that prevented it to handle NaN values.

## [3.5.0] 2025-07-09

### Changed

- ETL_engineering: 
    - `ColumnCleaner` will now be a configuration object that defines cleaning rules for a single Polars DataFrame column.
    - `DataFrameCleaner` will now orchestrate cleaning multiple columns in a Polars DataFrame by using `ColumnCleaner` objects.

## [3.4.0] - 2025-07-08

### Changed

- utilities: `serialize_object()` now returns None.

### Added

- utilities: `train_dataset_orchestrator()` orchestrates the creation of single-target datasets from multiple directories each with a variable number of CSV datasets.

## [3.3.0] - 2025-07-07

### Added

- data_exploration: `drop_zero_only_columns()` removes columns from a pandas DataFrame that contain only zeros and null/NaN values.
- ETL_engineering: `MultiBinaryDummifier` one-to-many transformer that creates multiple binary columns from a single text column based on a list of keywords.

### Fixed

- ETL_engineering: `KeywordDummifier` rollback behavior, dropping columns will cause issues with the DataProcessor.

## [3.2.1] - 2025-07-07

### Added

- ~~ETL_engineering: `KeywordDummifier` can drop empty columns before returning the dataframe.~~

## [3.2.0] - 2025-07-07

### Added

- ETL_engineering: `BinaryTransformer` maps string values to a binary 1 or 0 based on keyword matching.

### Changed

- ETL_engineering: 
    - `KeywordDummifier` support for case insensitive regex.
    - `RegexMapper` support for case insensitive regex.

## [3.1.0] - 2025-07-07

### Changed

- ETL_engineering: `ColumnCleaner` now supports sub-string replacements with backreferences, as well as default case insensitivity.

## [3.0.0] - 2025-07-06

### Changed

- "trainer" revamped into the following modules using PyTorch:
    - ML_trainer, Uses the main class `MyTrainer` to train PyTorch models. It imports ML_callbacks and ML_evaluation helpers.
    - ML_callbacks, Includes callbacks to use during model training.
    - ML_evaluation, Helper functions to visualize training and evaluation metrics.
    - ML_tutorial, produces a notebook script with a tutorial on how to use these modules.
    - RNN_forecast, `rnn_forecast()` runs a sequential forecast for a trained RNN-based model.

- "datasetmaster" and "vision_helpers" merged and revamped into the new module "datasetmaster" with the following classes:
    - `DatasetMaker`Creates processed PyTorch datasets from a Pandas DataFrame using a fluent, step-by-step interface.
    - `VisionDatasetMaker` Creates processed PyTorch datasets for computer vision tasks from an image folder directory.
    - `SequenceMaker` Creates windowed PyTorch datasets from time-series data.
    - `ResizeAspectFill` Custom transformation to make an image square.

- Update most scripts to work with the package logger when printing messages, warnings, and errors.

## [2.4.0] - 2025-07-03

### Added

- Optional dependency: `FreeSimpleGUI`
- New Module: "GUI_tools":
    - `PathManager` Manages paths for a Python application, supporting both development mode and bundled mode via Briefcase.
    - `ConfigManager` Loads a .ini file and provides access to its configuration values as object attributes.
    - `GUIFactory` Builds styled FreeSimpleGUI elements and layouts using a "building block" approach, driven by a ConfigManager instance.
    - `catch_exceptions()` A decorator that wraps a function in a try-except block. If an exception occurs, it's caught and displayed in a popup window.
    - `prepare_feature_vector()` Validates and converts GUI values into a numpy array for ML inference.
    - `update_target_fields()` Updates the GUI's target fields with inference results.

## [2.3.0] - 2025-07-02

### Added

- ETL_engineering: 
    - `RegexMapper` A transformer that maps string categories to numerical values based on a dictionary of regular expression patterns.
    - `RatioCalculator` A transformer that parses a string ratio and computes the result of the division.
    - `ColumnCleaner` Cleans and standardizes a single pandas Series based on a dictionary of regex-to-value replacement rules.
    - `DataFrameCleaner` Orchestrates the cleaning of multiple columns in a pandas DataFrame using a nested dictionary of rules and `ColumnCleaner` objects.

- PSO_optimization: `plot_optimal_feature_distributions()` Analyzes optimization results and plots the distribution of optimal values for each feature.

### Changed

- PSO_optimization: `run_pso()` Refactor, add logger, add dynamic inertia weight for faster convergence.

## [2.2.1] - 2025-06-30

### Added

- data_exploration: `standardize_percentages()` Standardizes numeric columns containing mixed-format percentages.
- ETL_engineering: `DataProcessor` now has a comprehensive `__str__`, call it through its method `.inspect()`.

### Fixed

- ETL_engineering: `CategoryMapper` fixed call method.

## [2.2.0] - 2025-06-30

### Fixed

- utilities: docstrings not referencing the new `pathlib.Path` objects handled.

### Added

- New module: "ETL_engineering": Extract, Transform, Load data using Polars backend.
    - `TransformationRecipe` A builder class for creating a data transformation recipe.
    - `DataProcessor` Transforms a Polars DataFrame based on a provided `TransformationRecipe` object.
    - `KeywordDummifier` A configurable transformer that creates one-hot encoded columns based on keyword matching in a Polars Series.
    - `NumberExtractor` A configurable transformer that extracts a single number from a Polars string series using a regular expression.
    - `MultiNumberExtractor` Extracts multiple numbers from a single Polars string column into several new columns.
    - `CategoryMapper` A transformer that maps string categories to specified numerical values using a dictionary.
    - `ValueBinner` A transformer that discretizes a continuous numerical Polars column into a finite number of bins.
    - `DateFeatureExtractor` A one-to-many transformer that extracts multiple numerical features from a Polars date or datetime column.

### Changed

- utilities: 
    - `load_dataframe()` can now load either Pandas or Polars dataframes.
    - `save_dataframe()` can now save either Pandas or Polars dataframes.

## [2.1.0] - 2025-06-26

### Added

- data_exploration: Full compatibility with `pathlib.Path` objects.
- ensemble_learning: Full compatibility with `pathlib.Path` objects.
- logger: Full compatibility with `pathlib.Path` objects.
- MICE_imputation: Full compatibility with `pathlib.Path` objects.
- PSO_optimization: Full compatibility with `pathlib.Path` objects.
- VIF_factor: Full compatibility with `pathlib.Path` objects.
- utilities: 
    - Full compatibility with `pathlib.Path` objects.
    - `make_fullpath()` resolves a string or Path into an absolute Path.
- handle_excel:
    - Full compatibility with `pathlib.Path` objects.
    - `find_excel_files()` returns a list of Excel file Paths in the specified directory.

### Changed

- data_exploration: `drop_rows_with_missing_data()` modified to inspect target columns and feature columns.

## [2.0.0] - 2025-06-25

### Changed

- Renamed module: "particle_swarm_optimization" to "_particle_swarm_optimization", deprecated.
- Moved `Pillow` from optional to base dependencies.
- Required Python version 3.10+.
- Updated README.
- Updated third party licenses.

### Added

- Package dependency: `tqdm>=4.0`
- utilities: `threshold_binary_values_batch` threshold the last binary columns of a 2D NumPy array to binary {0,1} using 0.5 cutoff.
- New module: "PSO_optimization"
- PSO_optimization: 
    - Calculate pso algorithm using PyTorch tensors in the backend.
    - New `ObjectiveFunction` class that suits the new backend.

## [1.4.8] - 2025-06-23

### Changed

- Clean and refactor imports from scripts.

## [1.4.7] - 2025-06-22

### Fixed

- PSO: Using deep copies of boundary values in `run_pso()` to avoid in-place modifications when executing the algorithm in a batch.

## [1.4.6] - 2025-06-22 

### Added

- data_exploration: `match_and_filter_columns_by_regex()` returns a tuple of (filtered DataFrame, matched column names) based on a regex pattern.
- utilities: `list_files_by_extension()` lists all files with the specified extension in a given directory and returns a mapping: filenames (without extensions) to their absolute paths.
- PSO: `multiple_objective_functions_from_dir()` loads multiple objective functions from serialized models in the given directory.

### Fixed

- data_exploration: `plot_correlation_heatmap()` will sanitize the title name only before saving the file.

## [1.4.5] - 2025-06-21

### Added

- utilities: `serialize_object()` and `deserialize_object()` to serialize objects using joblib.

### Changed

- utilities: `threshold_binary_values()` now returns the same data type as the input type.
- ensemble_learning: make use of `serialize_object()` from utilities.
- PSO: make use of `deserialize_object()` from utilities.
- MICE: `apply_mice()` correctly thresholds binary columns after imputation.
- data_exploration: 
    - `distribute_datasets_by_target()`, enhanced functionality and moved to "utilities".
    - `split_features_targets()` return order swapped to (df_features, df_targets).

## [1.4.4] - 2025-06-20

### Added

- data_exploration: `distribute_datasets_by_target()` now has a verbose boolean parameter.
- VIF: `compute_vif()` now has a verbose boolean parameter.

### Fixed

- data_exploration: `drop_columns_with_missing_data()` correctly displays the state of columns with nulls after the drop.

### Changed

- MICE: `apply_mice()` will name imputed datasets with the "_MICE" suffix.
- VIF: `compute_vif_multi()` will name imputed datasets with the "_VIF" suffix.
- ensemble_learning: LightGBM now uses 'gbdt' boosting.
- PSO: `run_pso()` set 1500 iterations as default.

## [1.4.3] - 2025-06-19

### Changed

- data_exploration: `drop_columns_with_missing_data()` has an option to display the state of columns with nulls after the drop.
- utilities: `merge_dataframes()` now accepts a "verbose" boolean.
- MICE: 
    - `run_mice_pipeline()` requires a list of target column names. Targets must be skipped from the imputation process. 
    - `save_imputed_datasets()` requires a DataFrame or Series with the target column(s) to merge before saving.
- ensemble_learning: 
    - `get_models()` replaced by classes `ClassificationTreeModels` and `RegressionTreeModels`.
    - Integrate new classes into the pipeline.
    - `dataset_yielder()` enhanced functionality.

### Added

- data_exploration: an iterator `distribute_datasets_by_target()` that yields a dataframe per target column, dropping rows with missing targets.

## [1.4.2] - 2025-06-19

### Changed

- ensemble_learning: Remove scalers, unnecessary for tree-based methods.
- PSO: 
    - Remove scalers.
    - `ObjectiveFunction`: Add noise only to continuous features.

### Fixed

- PSO: 
    - `run_pso()` correctly flips the sign of the target in the last iteration if "maximization" was used.
    - `run_pso()` correctly saves binary values.

### Added

- utilities: `threshold_binary_values()` accepts a 1D sequence and returns a numpy 1D array.

## [1.4.1] - 2025-06-19

### Changed

- handle_excel: sanitize filenames before saving files.
- data_exploration: `merge_dataframes()` moved to "utilities".
- VIF_factor: 
    - `drop_vif_based()` now returns the names of the dropped columns.
    - `compute_vif_multi()` will not save CSV files if there was no dropped columns.

### Fixed

- ensemble_learning: use sanitized filenames before attempting to save files.
- PSO: 
    - sanitize filenames before saving.
    - fix binary-continuous handling inside the ObjectiveFunction class.
    - Refine `run_pso()` logic.
    - Under testing and **unusable** at the moment.

### Added

- PSO: `run_pso()` can now automatically add lower and upper boundaries for binary features. 
- `info()` for all scripts.

### Deleted

- trainer: deprecated method.

## [1.4.0] - 2025-06-17

### Added

- VIF_factor:
    - `compute_vif()` revamped. Additionally, it now accepts an optional filename when saving a plot, and a maximum number of features to plot.
    - `compute_vif()` will correctly handle perfect multicollinearity and suppress warnings.
    - `compute_vif_multi()` function to automate the process.
- Dependency: `ipywidgets`

### Changed

- MICE_imputation: 
    - keep original feature names for metric plots, sanitize before saving them.
    - Update usage of `list_csv_paths()` with the new return type.
- utilities: 
    - `list_csv_paths()` now returns a dictionary {name, path}. 
    - `save_dataframe()` now warns about and skips empty dataframes.
- data_exploration: 
    - VIF related functions moved to "VIF_factor".
    - `save_dataframe()` moved to "utilities".
- ensemble_learning:
    - `run_pipeline()` renamed to `run_ensemble_pipeline()`.
    - Use a unique "base_fontsize" for plotting functions.
    - `get_shap_values()` outputs bar and dot plots.

### Fixed

- Bugs in the ensemble_learning pipeline.
- Bugs in the MICE_imputation pipeline.

## [1.3.2] - 2025-06-16

### Changed

- MICE Imputation
    - Pin dependency `miceforest>=6.0.0,<7.0.0`.
    - Pin dependency version `lightgbm<=4.5.0`.
    - Pin dependency `plotnine>=0.12,<0.13`.

### Fixed

- MICE Imputation script bugs.

### Added

- Notebook dependencies:
    - "ipykernel"
    - "notebook"
    - "jupyterlab"

## [1.3.1] - 2025-06-16

### Fixed

- Correctly list "imbalanced-learn" as a dependency instead of "imblearn".

## [1.3.0] - 2025-06-16

### Changed

- Revamped base and optional dependencies, only pytorch-related are optional. 
- Set requirement `numpy<2.0` for broad compatibility (including miceforest v6).
- Update README with conda-forge installation.

## [1.2.1] - 2025-06-16

### Deleted

- 'load.dataframe()' from 'data_exploration.py'.

### Changed

- 'yield_dataframes()' from 'ensemble_learning.py'. Uses the 'utilities.yield_dataframes_from_dir()' instead.

## [1.2.0] - 2025-06-15

### Added

- \[full\] option to download all dependencies on installation.

### Fixed

- Bugs in local import paths.

### Changed

- README file to clearly display installation and usage.

## [1.1.6] - 2025-06-13

### Added

- MIT "LICENSE" file.

### Changed

- Update reference to license to adhere to the new format of SPDX license expression.

## [1.1.5] - 2025-06-12

### Added

- Default dependencies for the project: numpy, pandas, matplotlib, scikit-learn.
- url-links in project

### Changed

- README.md example usage.

## [1.1.1] - 2025-06-12

### Fixed

- Incorrect metadata in "pyproject.toml".

## [1.1.0] - 2025-06-12

### Added

- Initial public release.
