{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dragon ML Toolbox - Regression Tutorial with DatasetMaker\n",
    "\n",
    "This notebook demonstrates the complete workflow for a **regression task** using the `dragon-ml-toolbox`. It showcases the new `DatasetMaker` for streamlined data preprocessing before training with `MyTrainer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "First, we import all necessary components. Notice the new import of `DatasetMaker` from `ml_tools.datasetmaster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from your dragon_ml_toolbox package\n",
    "from ml_tools.datasetmaster import DatasetMaker\n",
    "from ml_tools.ML_trainer import MyTrainer\n",
    "from ml_tools.ML_callbacks import EarlyStopping, ModelCheckpoint\n",
    "from ml_tools.keys import LogKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Device\n",
    "\n",
    "We'll automatically select the best available hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the Data with `DatasetMaker`\n",
    "\n",
    "Here, we'll generate a synthetic regression dataset and use the fluent interface of `DatasetMaker` to process it in a few simple steps. This replaces the need for manual splitting and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic dataset with continuous and categorical features\n",
    "X, y, *_ = make_regression(\n",
    "    n_samples=1000, \n",
    "    n_features=10, \n",
    "    n_informative=7, \n",
    "    noise=25,\n",
    "    random_state=42\n",
    ")\n",
    "X = pd.DataFrame(X, columns=[f'cont_feature_{i+1}' for i in range(10)])\n",
    "\n",
    "# Add some categorical features for a more realistic example\n",
    "X['cat_feature_1'] = pd.cut(X['cont_feature_1'], bins=4, labels=['A', 'B', 'C', 'D'])\n",
    "X['cat_feature_2'] = np.random.choice(['TypeX', 'TypeY', 'TypeZ'], size=1000)\n",
    "\n",
    "# Combine features and target into a single DataFrame\n",
    "df = X.copy()\n",
    "df['target'] = y\n",
    "\n",
    "print(\"Original data sample:\")\n",
    "display(df.head())\n",
    "\n",
    "# --- Use DatasetMaker for preprocessing ---\n",
    "maker = DatasetMaker(pandas_df=df, label_col='target')\n",
    "\n",
    "maker.process_categoricals(method='one-hot', drop_first=True) \\\n",
    "     .split_data(test_size=0.2, random_state=42) \\\n",
    "     .normalize_continuous(method='standard')\n",
    "\n",
    "# Get the final PyTorch datasets\n",
    "train_dataset, test_dataset = maker.get_datasets()\n",
    "\n",
    "# We can also inspect the processed dataframes to get feature names and shapes\n",
    "X_train_df, X_test_df, y_train_s, y_test_s = maker.inspect_dataframes()\n",
    "\n",
    "print(\"\\nShape of processed training features:\", X_train_df.shape)\n",
    "print(\"Shape of processed testing features:\", X_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Model, Criterion, and Optimizer\n",
    "\n",
    "The model's input layer size is now determined by the shape of the processed data from `DatasetMaker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self, input_features, output_features=1):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(input_features, 128)\n",
    "        self.layer_2 = nn.Linear(128, 64)\n",
    "        self.layer_3 = nn.Linear(64, output_features)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        return self.layer_3(x)\n",
    "\n",
    "# Get the number of input features from our processed training data\n",
    "input_size = X_train_df.shape[1]\n",
    "\n",
    "# Instantiate the components\n",
    "model = SimpleRegressor(input_features=input_size)\n",
    "criterion = nn.MSELoss() # Mean Squared Error is common for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Callbacks\n",
    "\n",
    "We'll configure `ModelCheckpoint` and `EarlyStopping` to monitor the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'checkpoints_regression'\n",
    "MONITOR_METRIC = LogKeys.VAL_LOSS\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    save_dir=CHECKPOINT_DIR,\n",
    "    monitor=MONITOR_METRIC,\n",
    "    save_best_only=True, \n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=MONITOR_METRIC,\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize the Trainer\n",
    "\n",
    "Instantiate `MyTrainer` with the datasets created by `DatasetMaker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset, # From DatasetMaker\n",
    "    test_dataset=test_dataset,   # From DatasetMaker\n",
    "    kind='regression', # Specify the task\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    callbacks=[model_checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n",
    "\n",
    "Call `.fit()` to start training. `MyTrainer` will handle the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.fit(epochs=100, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate the Model\n",
    "\n",
    "Load the best model and call `.evaluate()` to generate and save a full performance report for our regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model saved by the callback\n",
    "best_model_path = model_checkpoint.last_best_filepath\n",
    "\n",
    "if best_model_path and best_model_path.exists():\n",
    "    print(f'Loading best model weights from: {best_model_path}')\n",
    "    trainer.model.load_state_dict(torch.load(best_model_path))\n",
    "else:\n",
    "    print('Warning: No best model found. Evaluating with the last model state.')\n",
    "\n",
    "# Define a directory to save all evaluation artifacts\n",
    "EVAL_DIR = Path('tutorial_results_regression') / 'evaluation_report'\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate(save_dir=EVAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Explain the Model\n",
    "\n",
    "Finally, use `.explain()` to generate SHAP plots. The feature names are taken directly from the processed DataFrame columns provided by `DatasetMaker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a directory to save all explanation artifacts\n",
    "EXPLAIN_DIR = Path('tutorial_results_regression') / 'explanation_report'\n",
    "\n",
    "# Generate and save SHAP summary plots\n",
    "trainer.explain(\n",
    "    explain_dataset=test_dataset, \n",
    "    n_samples=100,\n",
    "    feature_names=X_train_df.columns.tolist(), # Get feature names from our processed DF\n",
    "    save_dir=EXPLAIN_DIR\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
